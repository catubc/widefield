{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import numpy as np\n",
    "\n",
    "# FUNCTION TO COMPUTE DFF\n",
    "import os\n",
    "from utility_classification import sum_pixels_in_registered_mask, fix_trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "from scipy.signal import butter, filtfilt, cheby1\n",
    "\n",
    "#select code 04/02/07 triggers;\n",
    "def get_triggers_for_body_movements_with_lockout(root_dir, \n",
    "                                                 recording, \n",
    "                                                 lockout_window,\n",
    "                                                 feature_name): \n",
    "    \n",
    "    # load the \n",
    "    fname_load = root_dir + '/tif_files/' + recording + '/spontaneous_starts_lockoutWindow_'+ str(lockout_window)+'_sec.npz'\n",
    "    try:\n",
    "        data_in = np.load(fname_load,allow_pickle=True)\n",
    "    except:\n",
    "        print (\"locs 44 thrshold missing\", fname_load)\n",
    "        return np.zeros((0),'float32'), np.zeros((0),'float32')\n",
    "    \n",
    "    feature_names = data_in['feature_names']\n",
    "    print (\"FEATURE NAMES: \", feature_names)\n",
    "    try:\n",
    "        idx = np.where(feature_names==feature_name)[0][0]\n",
    "        \n",
    "        locs_selected = data_in['feature_start_times_all'][idx]\n",
    "        locs_selected_with_lockout = data_in['feature_start_times_lockout'][idx]        \n",
    "        \n",
    "    except:\n",
    "        print (\"Could not find feature: \", feature_name)\n",
    "        locs_selected = np.zeros(0)\n",
    "        locs_selected_with_lockout = np.zeros(0)\n",
    "    # \n",
    "\n",
    "\n",
    "    return locs_selected, locs_selected_with_lockout\n",
    "    \n",
    "\n",
    "\n",
    "#select code 04/02/07 triggers;\n",
    "def get_04_triggers_with_lockout(root_dir, recording, lockout_window=10):\n",
    "    \n",
    "    # make sure locs\n",
    "    try:\n",
    "        locs_44threshold = np.load(root_dir + '/tif_files/' + recording + '/' + recording + '_locs44threshold.npy')\n",
    "    except:\n",
    "        print (\"locs 44 thrshold missing\", recording)\n",
    "        return np.zeros((0),'float32'), np.zeros((0),'float32')\n",
    "        \n",
    "    codes = np.load(root_dir + '/tif_files/' + recording + '/'+recording + '_code44threshold.npy')\n",
    "    code = b'04'\n",
    "    idx = np.where(codes==code)[0]\n",
    "    locs_selected = locs_44threshold[idx]\n",
    "\n",
    "    if locs_selected.shape[0]==0:\n",
    "        return np.zeros((0),'float32'), np.zeros((0),'float32')\n",
    "\n",
    "    diffs = locs_selected[1:]-locs_selected[:-1]\n",
    "    idx = np.where(diffs>lockout_window)[0]\n",
    "    \n",
    "    locs_selected_with_lockout = locs_selected[idx+1] \n",
    "    if locs_selected_with_lockout.shape[0]==0:\n",
    "        return np.zeros((0),'float32'), np.zeros((0),'float32')\n",
    "\n",
    "    # ADD FIRST VAL\n",
    "    if locs_selected[0]>lockout_window:\n",
    "        locs_selected_with_lockout = np.concatenate(([locs_selected[0]], locs_selected_with_lockout), axis=0)\n",
    "\n",
    "    return locs_selected, locs_selected_with_lockout\n",
    "    \n",
    "\n",
    "def find_nearest(array, value):\n",
    "    return (np.abs(array-value)).argmin()\n",
    "\n",
    "def load_reclength(filename):\n",
    "    \"\"\" Load realtime length of a single session. Probably should be in session, but was quicker to dump here\"\"\"\n",
    "\n",
    "    #print (\"FILENAME: \", filename)\n",
    "    text_file = open(filename, \"r\")\n",
    "    lines = text_file.read().splitlines()\n",
    "    event_text = []\n",
    "    for line in lines:\n",
    "        event_text.append(re.split(r'\\t+',line))\n",
    "\n",
    "    #Delete false starts from event file\n",
    "    for k in range(len(event_text)-1,-1,-1):        #Search backwards for the 1st occurence of \"date\" indicating last imaging start\n",
    "                                                    #NB: There can be multiple false starts WHICH DON\"T LINE UP - NEED TO IGNORE SUCH SESSIONS\n",
    "        if event_text[k][0]=='date': \n",
    "            event_text = event_text[k+2:]         #Remove first 2 lines\n",
    "            break\n",
    "\n",
    "    if len(event_text)==0:\n",
    "        reclength = 0\n",
    "    else:\n",
    "        if event_text[-1][2] != \"None\": \n",
    "            reclength = 0\n",
    "        else: \n",
    "            reclength = float(event_text[-1][3])\n",
    "\n",
    "    return reclength\n",
    "    \n",
    "\n",
    "# FUNCTION TO COMPUTE DFF\n",
    "def compute_DFF_function(\n",
    "                        root_dir,\n",
    "                        dff_method, # 'globalAverage' or 'slidingWindow'\n",
    "                        recording,\n",
    "                        locs_selected,\n",
    "                        n_sec_window = 10\n",
    "                        ):\n",
    "\n",
    "    \n",
    "    # ###################################################\n",
    "    # ###################################################\n",
    "    # ###################################################\n",
    "    # SET DEFAULT PARAMETERS\n",
    "    #n_sec_window = 10\n",
    "    low_cut = 0.1\n",
    "    high_cut = 6.0\n",
    "    img_rate = np.loadtxt(root_dir+'/img_rate.txt')\n",
    "    selected_dff_filter = 'butterworth'\n",
    "\n",
    "    # MAKE FILENAMES\n",
    "    tif_files = root_dir+'/tif_files.npy'\n",
    "    event_files = root_dir + '/event_files.npy'\n",
    "    aligned_fname = root_dir + '/tif_files/'+recording + '/'+recording + \"_aligned.npy\"\n",
    "    #print (\"aligned fname: \", aligned_fname)\n",
    "\n",
    "    rec_filename = root_dir + '/tif_files/'+recording + '/'+recording +'.tif'\n",
    "    #print (\"rec_fileame;\", rec_filename)\n",
    "    n_sec = float(n_sec_window)\n",
    "        \n",
    "    # Load aligned/filtered data and find ON/OFF light;\n",
    "    #images_file = self.parent.animal.home_dir+self.parent.animal.name+'/tif_files/'+self.rec_filename+'/'+self.rec_filename+'_aligned.npy'\n",
    "    images_file = aligned_fname\n",
    "    try:\n",
    "        aligned_images = np.load(images_file)\n",
    "    except:\n",
    "        print (\"missing aligned images - skipping session\", recording)\n",
    "        return np.zeros((0),'float32')\n",
    "\n",
    "    \n",
    "    # Find blue light on/off \n",
    "    blue_light_threshold = 400  #Intensity threshold; when this value is reached - imaging light was turned on\n",
    "    start_blue = 0; end_blue = len(aligned_images)\n",
    "    \n",
    "    if np.average(aligned_images[0])> blue_light_threshold:    #Case #1: imaging starts with light on; need to remove end chunk; though likely bad recording\n",
    "        for k in range(len(aligned_images)):\n",
    "            if np.average(aligned_images[k])< blue_light_threshold:\n",
    "                #self.aligned_images = self.aligned_images[k:]\n",
    "                end_blue = k\n",
    "                break\n",
    "    else:                                                           #Case #2: start with light off; remove starting and end chunks;\n",
    "        #Find first light on\n",
    "        for k in range(len(aligned_images)):\n",
    "            if np.average(aligned_images[k])> blue_light_threshold:\n",
    "                start_blue = k\n",
    "                break\n",
    "\n",
    "        #Find light off - count backwards from end of imaging data\n",
    "        for k in range(len(aligned_images)-1,0,-1):\n",
    "            if np.average(aligned_images[k])> blue_light_threshold:\n",
    "                end_blue= k\n",
    "                break\n",
    "                \n",
    "                \n",
    "    #self.lowcut = float(self.parent.filter_low.text())\n",
    "    #self.highcut = float(self.parent.filter_high.text())\n",
    "        \n",
    "    #if self.selected_dff_filter == 'nofilter':\n",
    "    #    pass; #already loaded nonfiltered self.aligned_images above\n",
    "    #else:\n",
    "    filtered_filename = images_file[:-4]+'_'+selected_dff_filter+'_'+str(low_cut)+'hz_'+str(high_cut)+'hz.npy'\n",
    "    if os.path.exists(filtered_filename):\n",
    "        try:\n",
    "            aligned_images = np.load(filtered_filename, allow_pickle=True)\n",
    "        except:\n",
    "            print (\"aligned filtered images corrupt... recomputing: \", filtered_filename)\n",
    "            filter_data(root_dir, recording)\n",
    "            aligned_images = np.load(filtered_filename)\n",
    "    else:\n",
    "        print (\"aligned filtered images missing... recomputing: \", filtered_filename)\n",
    "        filter_data(root_dir, recording)\n",
    "        aligned_images = np.load(filtered_filename)\n",
    "        \n",
    "    aligned_images = aligned_images[start_blue:end_blue]\n",
    "    \n",
    "    # compute # of images in stack\n",
    "    n_images=len(aligned_images)\n",
    "\n",
    "\n",
    "    # Determine if imaging rate correct \n",
    "    temp_tif_files = np.load(tif_files)\n",
    "    temp_event_files = np.load(event_files)\n",
    "    if len(temp_event_files)==1:\n",
    "        temp_event_files = temp_event_files[0]\n",
    "    #print (\"temp_tif files;l\", temp_tif_files)\n",
    "    #print (\"rec_filename: \", rec_filename)\n",
    "\n",
    "    index = None\n",
    "    for k in range(len(temp_tif_files)):\n",
    "        try:\n",
    "            temp_temp = temp_tif_files[k].decode(\"utf-8\").replace('12TB/in_vivo/tim','4TBSSD').replace(\n",
    "                                                    '10TB/in_vivo/tim','4TBSSD')#.replace(\"b'/\", \"'/\")\n",
    "        except:\n",
    "            temp_temp = temp_tif_files[k].replace('12TB/in_vivo/tim','4TBSSD').replace(\n",
    "                                                    '10TB/in_vivo/tim','4TBSSD')#.replace(\"b'/\", \"'/\")\n",
    "        if rec_filename in temp_temp:\n",
    "            index = k \n",
    "            break\n",
    "    \n",
    "    if index == None:\n",
    "        \n",
    "        print (\"DID NOT FIND MATCH between imaging and lever ---- RETURNING \")\n",
    "        #print (temp_tif_files)\n",
    "        return np.zeros((0),'float32')\n",
    "    \n",
    "    #print (\"INDEX: \", index)\n",
    "    #print (\"temp event files indexed: \", len(temp_event_files[index]))\n",
    "    # load the reclength based \n",
    "    try:\n",
    "        reclength = load_reclength(temp_event_files[index].decode(\"utf-8\").replace(\n",
    "                                                    '10TB/in_vivo/tim','4TBSSD'))\n",
    "    except:\n",
    "        reclength = load_reclength(temp_event_files[index].replace(\n",
    "                                                    '10TB/in_vivo/tim','4TBSSD'))\n",
    "\n",
    "    if reclength ==0:\n",
    "        print (\"zero length recording exiting (excitation light failure)\", recording)\n",
    "        return np.zeros((0),'float32')\n",
    "    \n",
    "    # compute imaging rate; \n",
    "    session_img_rate = n_images/reclength\n",
    "\n",
    "    if abs(session_img_rate-float(img_rate))<0.01:         #Compare computed session img_rate w. experimentally set img_rate\n",
    "        np.save(images_file.replace('_aligned.npy','')+'_img_rate', session_img_rate)\n",
    "    else:\n",
    "        np.save(images_file.replace('_aligned.npy','')+'_img_rate', session_img_rate)\n",
    "        print (\"Imaging rates between aligned and session are incorrect, exiting: \", session_img_rate)\n",
    "        return np.zeros((0),'float32')\n",
    "\n",
    "\n",
    "    # Find times of triggers from lever pull threshold times\n",
    "    trigger_times = locs_selected\n",
    "    frame_times = np.linspace(0, reclength, n_images)             #Divide up reclength in number of images\n",
    "    img_frame_triggers = []\n",
    "    for i in range(len(trigger_times)):\n",
    "        #img_frame_triggers.append(self.find_previous(frame_times, trigger_times[i])) \n",
    "        img_frame_triggers.append(find_nearest(frame_times, trigger_times[i]))     #Two different functions possible here; \n",
    "    \n",
    "    #BASELINE FOR GLOBAL BASELINE REMOVAL\n",
    "    mean_file = root_dir + '/tif_files/'+recording + '/'+recording + '_aligned_mean.npy'\n",
    "    if os.path.exists(mean_file)==False:\n",
    "        aligned_fname = root_dir + '/tif_files/'+recording + '/'+recording + \"_aligned.npy\"\n",
    "        images_file = aligned_fname\n",
    "        images_aligned = np.load(images_file)\n",
    "        images_aligned_mean = np.mean(images_aligned, axis=0)\n",
    "        np.save(images_file[:-4]+'_mean', images_aligned_mean)\n",
    "\n",
    "    global_mean = np.load(mean_file)\n",
    "\n",
    "    abstimes = np.load(root_dir + '/tif_files/'+recording + '/'+recording + '_abstimes.npy')\n",
    "    abspositions = np.load(root_dir + '/tif_files/'+recording + '/'+recording + '_abspositions.npy')\n",
    "\n",
    "    data_stm = []; traces = []; locs = []; codes = []\n",
    "    counter=-1\n",
    "    window = n_sec * session_img_rate      #THIS MAY NOT BE GOOD ENOUGH; SHOULD ALWAYS GO BACK AT LEAST X SECONDS EVEN IF WINDOW IS ONLY 1SEC or 0.5sec...\n",
    "                                                            #Alternatively: always compute using at least 3sec window, and then just zoom in\n",
    "    for trigger in img_frame_triggers:\n",
    "        counter+=1\n",
    "        #NB: Ensure enough space for the sliding window; usually 2 x #frames in window\n",
    "        if trigger < (2*window) or trigger>(n_images-window): \n",
    "            continue  #Skip if too close to start/end\n",
    "\n",
    "        #add locs and codes\n",
    "        #locs.append(locs_44threshold_selected[counter])\n",
    "        #codes.append(code_44threshold_selected[counter])\n",
    "\n",
    "        # load data chunk working with\n",
    "        data_chunk = aligned_images[int(trigger-window):int(trigger+window)]\n",
    "\n",
    "        if dff_method == 'globalAverage':\n",
    "            data_stm.append((data_chunk-global_mean)/global_mean)    #Only need to divide by global mean as original data_chunk did not have mean img added in\n",
    "            \n",
    "        elif dff_method == 'slidingWindow':            #Use baseline -2*window .. -window\n",
    "            baseline = np.average(aligned_images[int(trigger-2*window):int(trigger-window)], axis=0)\n",
    "            data_stm.append((data_chunk-baseline)/baseline)\n",
    "        \n",
    "        #***PROCESS TRACES - WORKING IN DIFFERENT TIME SCALE\n",
    "        lever_window = int(120*n_sec)    #NB: Lever window is computing in real time steps @ ~120Hz; and discontinuous;\n",
    "        t = np.linspace(-lever_window*0.0082,\n",
    "                        lever_window*0.0082, \n",
    "                        lever_window*2)\n",
    "        #lever_position_index = find_nearest(np.array(self.abstimes), self.locs_44threshold[counter])\n",
    "        lever_position_index = find_nearest(np.array(abstimes), locs_selected[counter])\n",
    "        \n",
    "        lever_trace = abspositions[int(lever_position_index-lever_window):int(lever_position_index+lever_window)]\n",
    "\n",
    "        if len(lever_trace)!=len(t):    #Extraplote missing data\n",
    "            lever_trace = np.zeros(lever_window*2,dtype=np.float32)\n",
    "            for k in range(-lever_window,lever_window,1):\n",
    "                lever_trace[k+lever_window] = self.abspositions[k+lever_window]     #Double check this...\n",
    "\n",
    "        traces.append(lever_trace)\n",
    "\n",
    "    data_stm = np.array(data_stm)\n",
    "    \n",
    "    return data_stm\n",
    "\n",
    "\n",
    "def filter_data(root_dir,\n",
    "                recording,\n",
    "                ):\n",
    "\n",
    "    \n",
    "    # ###################################################\n",
    "    # ###################################################\n",
    "    # ###################################################\n",
    "    # SET DEFAULT PARAMETERS\n",
    "    #n_sec_window = 10\n",
    "    low_cut = 0.1\n",
    "    high_cut = 6.0\n",
    "    img_rate = 30.0\n",
    "    selected_dff_filter = 'butterworth'\n",
    "\n",
    "    # MAKE FILENAMES\n",
    "    generic_mask_fname = root_dir + '/genericmask.txt'\n",
    "    tif_files = root_dir+'tif_files.npy'\n",
    "    event_files = root_dir + 'event_files.npy'\n",
    "    aligned_fname = root_dir + '/tif_files/'+recording + '/'+recording + \"_aligned.npy\"\n",
    "    \n",
    "    #print (\"FILTERING DATA: \", aligned_fname)\n",
    "    \n",
    "    # FILTERING STEP\n",
    "    images_file = aligned_fname\n",
    "    \n",
    "    filter_type = selected_dff_filter\n",
    "    lowcut = low_cut\n",
    "    highcut = high_cut\n",
    "    fs = img_rate\n",
    "\n",
    "    #Check to see if data requested exists- THIS CHECK WAS ALREADY DONE PRIOR TO ENTERING FUNCTION\n",
    "    if False:\n",
    "        if os.path.exists(images_file[:-4]+'_'+filter_type+'_'+str(lowcut)+'hz_'+str(highcut)+'hz.npy'):\n",
    "            #print (\"filtered data already exists...\")\n",
    "            return\n",
    "\n",
    "    #Load aligned images\n",
    "    if os.path.exists(images_file):\n",
    "        images_aligned = np.load(images_file)\n",
    "    else:\n",
    "        print (\" ...missing aligned images... NEED TO RUN ALIGN ALGORITHMS\", images_file)\n",
    "        return None\n",
    "        \n",
    "        # TODO IMPLMENET ALIGNMENT TOOL\n",
    "        #images_aligned = align_images2(self)\n",
    "        \n",
    "    #Save mean of images_aligned if not already done\n",
    "    if os.path.exists(images_file[:-4]+'_mean.npy')==False: \n",
    "        images_aligned_mean = np.mean(images_aligned, axis=0)\n",
    "        np.save(images_file[:-4]+'_mean', images_aligned_mean)\n",
    "    else:\n",
    "        images_aligned_mean = np.load(images_file[:-4]+'_mean.npy')\n",
    "            \n",
    "    #Load mask - filter only datapoints inside mask\n",
    "    n_pixels = len(images_aligned[0])\n",
    "    generic_coords = np.loadtxt(generic_mask_fname)\n",
    "    generic_mask_indexes=np.zeros((n_pixels,n_pixels))\n",
    "    for i in range(len(generic_coords)): generic_mask_indexes[int(generic_coords[i][0])][int(generic_coords[i][1])] = True\n",
    "\n",
    "    #Filter selection and parameters\n",
    "    if filter_type == 'butterworth':\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        order = 2\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "    elif filter_type == 'chebyshev':\n",
    "        nyq = fs / 2.0\n",
    "        order = 4\n",
    "        rp = 0.1\n",
    "        Wn = [lowcut / nyq, highcut / nyq]\n",
    "        b, a = cheby1(order, rp, Wn, 'bandpass', analog=False)\n",
    "    \n",
    "    \n",
    "    #Load individual pixel time courses; SWITCH TO UNRAVEL HERE****\n",
    "    import time\n",
    "   \n",
    "    filtered_array = np.zeros(images_aligned.shape, dtype=np.float16)\n",
    "    now = time.time(); start_time = now\n",
    "    cutoff=n_pixels\n",
    "    #from tqdm import tqdm\n",
    "    #for p1 in tqdm(range(n_pixels)):\n",
    "    for p1 in range(n_pixels):\n",
    "        now=time.time(); n_pixels_in=0\n",
    "        for p2 in range(n_pixels):\n",
    "            if generic_mask_indexes[p1,p2]==False:\n",
    "                filtered_array[:,p1,p2] = np.float16(filtfilt(b, a, images_aligned[:,p1,p2])); n_pixels_in+=1   #filter pixel inside mask\n",
    "        \n",
    "    np.save(images_file[:-4]+'_'+filter_type+'_'+str(lowcut)+'hz_'+str(highcut)+'hz', \n",
    "            filtered_array+np.float16(images_aligned_mean))\n",
    "\n",
    "    return \n",
    "\n",
    "def compute_trial_courses_ROI(recording, root_dir):\n",
    "\n",
    "    #try: \n",
    "        fname_04 = root_dir + '/tif_files/' + recording + \"_data_04_code_trial_timeCourses.npy\"\n",
    "        fname_random = root_dir + '/tif_files/' + recording + \"_data_random_code_trial_timeCourses.npy\"\n",
    "\n",
    "        # SET PARAMETERS\n",
    "        n_sec_window = 10\n",
    "        dff_method = 'globalAverage'\n",
    "\n",
    "        if os.path.exists(fname_04)==False:\n",
    "            # select code 04/02/07 triggers;\n",
    "            try:\n",
    "                locs_44threshold = np.load(root_dir + '/tif_files/' + recording + '/' + recording + '_locs44threshold.npy')\n",
    "            except:\n",
    "                print (\"locs 44 thrshold missing\", recording)\n",
    "                return None\n",
    "            \n",
    "            codes = np.load(root_dir + '/tif_files/' + recording + '/'+recording + '_code44threshold.npy')\n",
    "            code = b'04'\n",
    "            idx = np.where(codes==code)[0]\n",
    "            locs_selected = locs_44threshold[idx]\n",
    "\n",
    "            # CALL FUNCTION;\n",
    "            data_stm = compute_DFF_function(\n",
    "                                    root_dir,\n",
    "                                    dff_method, # 'globalAverage' or 'slidingWindow'\n",
    "                                    recording,\n",
    "                                    locs_selected,\n",
    "                                    n_sec_window\n",
    "                                    )\n",
    "            if data_stm is None:\n",
    "                print (\"data_stm is None\", recording)\n",
    "                return\n",
    "\n",
    "\n",
    "            # CONVERT DATA FROM 128 x 128 to 35 ROIs\n",
    "\n",
    "            # load Allen Institute afine transformation to scale data\n",
    "            #maskwarp= np.load('/media/cat/4TBSSD/yuki/IA2/tif_files/IA2pm_Apr22_Week2_30Hz/IA2pm_Apr22_Week2_30Hz_aligned_maskwarp.npy')\n",
    "            maskwarp = np.load('/home/cat/maskwarp.npy')\n",
    "\n",
    "            # accumulate mean activity in each ROI\n",
    "            # input data shape: [# trials, # times, width, height]\n",
    "            area_ids, trial_courses = sum_pixels_in_registered_mask(data_stm, maskwarp)\n",
    "\n",
    "            # generate random time corses\n",
    "            locs_selected = np.float32(np.linspace(30, 1200, data_stm.shape[0]))\n",
    "            locs_selected = locs_selected + np.random.rand(locs_selected.shape[0])*10-5      \n",
    "\n",
    "            # CALL FUNCTION;\n",
    "            data_stm_random = compute_DFF_function(\n",
    "                                    root_dir,\n",
    "                                    dff_method, # 'globalAverage' or 'slidingWindow'\n",
    "                                    recording,\n",
    "                                    locs_selected,\n",
    "                                    n_sec_window\n",
    "                                    )\n",
    "            if data_stm_random is None:\n",
    "                return\n",
    "\n",
    "            # compute random trial time courses\n",
    "            _, trial_courses_random = sum_pixels_in_registered_mask(data_stm_random, maskwarp)\n",
    "\n",
    "            #####################################################################\n",
    "            ######## REMOVE INFINITIES, NANS ETC FROM DATA ######################\n",
    "            #####################################################################\n",
    "            if trial_courses.shape[0]==0:\n",
    "                return\n",
    "            \n",
    "            trial_courses_fixed, trial_courses_random_fixed = fix_trials(trial_courses, trial_courses_random)\n",
    "\n",
    "            np.save(fname_04+ \"_area_ids.npy\", area_ids)\n",
    "            np.save(fname_04, trial_courses_fixed)\n",
    "            #print (\"Saved DFF for triggered data: \", fname_04, trial_courses_fixed.shape)\n",
    "\n",
    "            #offset = DLC_offset\n",
    "            np.save(fname_random, trial_courses_random_fixed)\n",
    "            #print (\"Saved DFF for random data: \", trial_courses_random_fixed.shape)\n",
    "    #except:\n",
    "    #    print (\"skipped: \", recording)\n",
    "    #    pass\n",
    "   # print ('')\n",
    "\n",
    "\n",
    "def compute_trial_courses_ROI_any_trigger(recording, \n",
    "                                          root_dir,\n",
    "                                          locs_selected,\n",
    "                                          feature_name,\n",
    "                                          n_sec_window=10):\n",
    "\n",
    "\n",
    "        # GENERATE SAVE FILENAMES \n",
    "        fname_04 = root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\"_trial_timeCourses.npy\"\n",
    "        fname_random = root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\"_random_ROItimeCourses.npy\"\n",
    "\n",
    "        # SET PARAMETERS\n",
    "        #n_sec_window = 10\n",
    "        dff_method = 'globalAverage'\n",
    "\n",
    "        if os.path.exists(fname_04)==False:\n",
    "\n",
    "            # CALL FUNCTION;\n",
    "            data_stm = compute_DFF_function(\n",
    "                                    root_dir,\n",
    "                                    dff_method, # 'globalAverage' or 'slidingWindow'\n",
    "                                    recording,\n",
    "                                    locs_selected,\n",
    "                                    n_sec_window\n",
    "                                    )\n",
    "            if data_stm is None:\n",
    "                print (\"data_stm is None\", recording)\n",
    "                return\n",
    "\n",
    "\n",
    "            # CONVERT DATA FROM 128 x 128 to 35 ROIs\n",
    "\n",
    "            # load Allen Institute afine transformation to scale data\n",
    "            #maskwarp= np.load('/media/cat/4TBSSD/yuki/IA2/tif_files/IA2pm_Apr22_Week2_30Hz/IA2pm_Apr22_Week2_30Hz_aligned_maskwarp.npy')\n",
    "            maskwarp = np.load('/home/cat/maskwarp.npy')\n",
    "\n",
    "            # accumulate mean activity in each ROI\n",
    "            # input data shape: [# trials, # times, width, height]\n",
    "            area_ids, trial_courses = sum_pixels_in_registered_mask(data_stm, maskwarp)\n",
    "\n",
    "            # generate random time corses\n",
    "            locs_selected = np.float32(np.linspace(30, 1200, data_stm.shape[0])) \n",
    "            locs_selected = locs_selected + np.random.rand(locs_selected.shape[0])*10-5      \n",
    "\n",
    "            # CALL FUNCTION;\n",
    "            data_stm_random = compute_DFF_function(\n",
    "                                    root_dir,\n",
    "                                    dff_method, # 'globalAverage' or 'slidingWindow'\n",
    "                                    recording,\n",
    "                                    locs_selected,\n",
    "                                    n_sec_window\n",
    "                                    )\n",
    "            \n",
    "            if data_stm_random is None:\n",
    "                return\n",
    "\n",
    "            # compute random trial time courses\n",
    "            _, trial_courses_random = sum_pixels_in_registered_mask(data_stm_random, maskwarp)\n",
    "\n",
    "            #####################################################################\n",
    "            ######## REMOVE INFINITIES, NANS ETC FROM DATA ######################\n",
    "            #####################################################################\n",
    "            if trial_courses.shape[0]==0:\n",
    "                return\n",
    "            \n",
    "            trial_courses_fixed, trial_courses_random_fixed = fix_trials(trial_courses, trial_courses_random)\n",
    "\n",
    "            np.save(fname_04+ \"_area_ids.npy\", area_ids)\n",
    "            np.save(fname_04, trial_courses_fixed)\n",
    "            #print (\"Saved DFF for triggered data: \", fname_04, trial_courses_fixed.shape)\n",
    "\n",
    "            #offset = DLC_offset\n",
    "            np.save(fname_random, trial_courses_random_fixed)\n",
    "            #print (\"Saved DFF for random data: \", trial_courses_random_fixed.shape)\n",
    "\n",
    "            \n",
    "\n",
    "def compute_trial_courses_ROI_code04_trigger(recording, \n",
    "                                          root_dir,\n",
    "                                          feature_names,\n",
    "                                          lockout_window,   # THIS IS THE LOCKOUT WINDOW FOR NO OTHER PULLS\n",
    "                                          n_sec_window,\n",
    "                                          compute_all_DFF_flag,\n",
    "                                          compute_lockout_DFF_flag,\n",
    "                                          recompute,\n",
    "                                          midline_filter_flag,\n",
    "                                          total_window):   # THIS IS THE DFF TIEM COURSE WINDOW; e.g. -10..+10sec\n",
    "\n",
    "\n",
    "    # SET PARAMETERS\n",
    "    #n_sec_window = 10\n",
    "    dff_method = 'globalAverage'  # TRY PRECEDING PERIOD ALSO!!!\n",
    "\n",
    "    for feature_name in feature_names:\n",
    "        locs_selected, locs_selected_with_lockout = get_triggers_for_body_movements_with_lockout(root_dir, \n",
    "                                                                                                 recording,\n",
    "                                                                                                 lockout_window,\n",
    "                                                                                                 feature_name)\n",
    "        # \n",
    "        shift = np.loadtxt(root_dir+'/tif_files/'+recording+'/shift.txt')\n",
    "        print (\"Shifting [ca] \", shift)\n",
    "        locs_selected = locs_selected-shift\n",
    "        locs_selected_with_lockout = locs_selected_with_lockout-shift\n",
    "\n",
    "        if compute_all_DFF_flag:\n",
    "            # GENERATE SAVE FILENAMES FOR ALL CODE_04 DATA\n",
    "            fname_04 = (root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\n",
    "                        \"_trial_ROItimeCourses_\"+str(total_window)+\"sec.npy\")\n",
    "\n",
    "            fname_random = (root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\n",
    "                            \"_random_ROItimeCourses_\"+str(total_window)+\"sec.npy\")\n",
    "\n",
    "            # good idea to save these as text to see them after:\n",
    "            np.savetxt(fname_04[:-4]+\"_locs_selected.txt\" , \n",
    "                       locs_selected,\n",
    "                       fmt='%s')\n",
    "\n",
    "\n",
    "            # \n",
    "            dff1, dff1_random = generate_arrays_ROI_triggered(root_dir,\n",
    "                                                                 dff_method,\n",
    "                                                                 recording,\n",
    "                                                                 locs_selected,\n",
    "                                                                 total_window,\n",
    "                                                                 fname_04,\n",
    "                                                                 fname_random,\n",
    "                                                                 recompute,\n",
    "                                                                 midline_filter_flag)\n",
    "\n",
    "        if compute_lockout_DFF_flag:\n",
    "            # GENERATE SAVE FILENAMES FOR LOCKOUT DATA\n",
    "            fname_04 = (root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\n",
    "                        \"_lockout_\"+str(lockout_window)+\"sec_trial_ROItimeCourses_\"+str(total_window)+\"sec.npy\")\n",
    "            fname_random = (root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\n",
    "                            \"_lockout_\"+str(lockout_window)+\"sec_random_ROItimeCourses_\"+str(total_window)+\"sec.npy\")\n",
    "\n",
    "            # good idea to save these as text to see them after:\n",
    "            np.savetxt(fname_04[:-4]+\"_locs_selected_with_lockout.txt\" , \n",
    "                       locs_selected_with_lockout,\n",
    "                       fmt='%s')\n",
    "            \n",
    "            #if os.path.exists(fname_04)==False:\n",
    "            dff2, dff2_random = generate_arrays_ROI_triggered(root_dir,\n",
    "                                                                 dff_method,\n",
    "                                                                 recording,\n",
    "                                                                 locs_selected_with_lockout,\n",
    "                                                                 total_window,\n",
    "                                                                 fname_04,\n",
    "                                                                 fname_random,\n",
    "                                                                 recompute,\n",
    "                                                                 midline_filter_flag)\n",
    "\n",
    "\n",
    "    # not necessary to return any data\n",
    "    #return dff1, dff1_random, dff2, dff2_random\n",
    "\n",
    "\n",
    "\n",
    "def load_trial_courses_ROI_code04_trigger(recording, \n",
    "                                          root_dir,\n",
    "                                          feature_name,\n",
    "                                          lockout_window,   # THIS IS THE LOCKOUT WINDOW FOR NO OTHER PULLS\n",
    "                                          n_sec_window):   # THIS IS THE DFF TIEM COURSE WINDOW; e.g. -10..+10sec\n",
    "\n",
    "\n",
    "    # GENERATE SAVE FILENAMES FOR ALL CODE_04 DATA\n",
    "    fname_04 = (root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\n",
    "                \"_trial_ROItimeCourses_\"+str(n_sec_window)+\"sec.npy\")\n",
    "\n",
    "    fname_random = (root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\n",
    "                    \"_random_ROItimeCourses_\"+str(n_sec_window)+\"sec.npy\")\n",
    "\n",
    "    data_04 = np.load(fname_04)\n",
    "    data_04_random = np.load(fname_random)\n",
    "\n",
    "        \n",
    "    # GENERATE SAVE FILENAMES FOR LOCKOUT DATA\n",
    "    fname_04 = (root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\n",
    "                \"_lockout_\"+str(lockout_window)+\"sec_trial_ROItimeCourses_\"+str(n_sec_window)+\"sec.npy\")\n",
    "    fname_random = (root_dir + '/tif_files/' + recording + '/' + recording + \"_\"+feature_name+\n",
    "                    \"_lockout_\"+str(lockout_window)+\"sec_random_ROItimeCourses_\"+str(n_sec_window)+\"sec.npy\")\n",
    "\n",
    "    \n",
    "    data_04_lockout = np.load(fname_04)\n",
    "    data_04_lockout_random = np.load(fname_random)\n",
    "    \n",
    "    \n",
    "    return data_04, data_04_random, data_04_lockout, data_04_lockout_random\n",
    "\n",
    "\n",
    "def compute_midline_filter(root_dir,\n",
    "                              data_stm):\n",
    "    import yaml\n",
    "\n",
    "    with open(os.path.join(root_dir,\"gcamp.txt\"), 'r') as f:\n",
    "        valuesYaml = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    val999 = valuesYaml['val999']\n",
    "    width = valuesYaml['width']\n",
    "    power = valuesYaml['power']\n",
    "    maxval = 10 # is not being used currently\n",
    "\n",
    "    # generate midline filter using t=0 to approximately t=0.5sec brain activity which most likely to generate midline blood pressure \n",
    "    # artifacts\n",
    "    #print (\"data stm: \", data_stm.shape)\n",
    "    midline_filter = motion_mask_parallel(data_stm.mean(0)[data_stm.shape[0]//2: \n",
    "                                                           data_stm.shape[0]//2+15].mean(0), \n",
    "                                          maxval,  # this value is not used\n",
    "                                          val999, \n",
    "                                          width, \n",
    "                                          power)\n",
    "\n",
    "    return midline_filter\n",
    "\n",
    "\n",
    "def correct_midline_artifact(data_stm,\n",
    "                            midline_filter):\n",
    "\n",
    "    # loop over all frames in data stack and filter out midline activity\n",
    "    for k in range(data_stm.shape[0]):\n",
    "        for p in range(data_stm.shape[1]):\n",
    "            data_stm[k,p] *=midline_filter\n",
    "\n",
    "    return data_stm \n",
    "\n",
    "\n",
    "def generate_arrays_ROI_triggered(root_dir,\n",
    "                                 dff_method,\n",
    "                                 recording,\n",
    "                                 locs_selected,\n",
    "                                 n_sec_window,\n",
    "                                 fname_04,\n",
    "                                 fname_random, \n",
    "                                 recompute,\n",
    "                                 midline_filter_flag):\n",
    "     \n",
    "    from tqdm import trange\n",
    "    \n",
    "    fname_04_data_stm = fname_04[:-4]+\"_all_brain.npy\"\n",
    "\n",
    "    if os.path.exists(fname_04)==False or recompute==True:\n",
    "        # CALL FUNCTION;\n",
    "        data_stm = compute_DFF_function(\n",
    "                                root_dir,\n",
    "                                dff_method, # 'globalAverage' or 'slidingWindow'\n",
    "                                recording,\n",
    "                                locs_selected,\n",
    "                                n_sec_window\n",
    "                                )\n",
    "        if data_stm.shape[0]==0:\n",
    "            print (\"data_stm is None\", recording)\n",
    "            return np.zeros((0), 'float32'), np.zeros((0), 'float32') \n",
    "        \n",
    "        # SAVE data_stm stack\n",
    "        if False:\n",
    "            np.save(fname_04_data_stm, data_stm)\n",
    "        \n",
    "        # \n",
    "        if midline_filter_flag:\n",
    "            midline_filter = compute_midline_filter(root_dir,\n",
    "                                              data_stm)\n",
    "            \n",
    "            data_stm = correct_midline_artifact(data_stm, \n",
    "                                                midline_filter)\n",
    "        \n",
    "        #####################################################\n",
    "        ###### CONVERT DATA FROM 128 x 128 to 35 ROIs #######\n",
    "        #####################################################\n",
    "        # load Allen Institute afine transformation to scale data\n",
    "        maskwarp = np.load('/home/cat/maskwarp.npy')\n",
    "\n",
    "        # accumulate mean activity in each ROI\n",
    "        # input data shape: [# trials, # times, width, height]\n",
    "        area_ids, trial_courses = sum_pixels_in_registered_mask(data_stm, maskwarp)\n",
    "\n",
    "        # generate random time corses\n",
    "        locs_selected = np.float32(np.linspace(30, 1200, data_stm.shape[0])) \n",
    "        locs_selected = locs_selected + np.random.rand(locs_selected.shape[0])*10-5      \n",
    "        data_stm = None\n",
    "\n",
    "        \n",
    "        # CALL FUNCTION;\n",
    "        data_stm_random = compute_DFF_function(\n",
    "                                root_dir,\n",
    "                                dff_method, # 'globalAverage' or 'slidingWindow'\n",
    "                                recording,\n",
    "                                locs_selected,\n",
    "                                n_sec_window\n",
    "                                )\n",
    "        \n",
    "        if data_stm_random is None:\n",
    "            return np.zeros((0), 'float32'), np.zeros((0), 'float32') \n",
    "\n",
    "        # use the same filter as in the event triggered neural activity\n",
    "        if midline_filter_flag:\n",
    "           \n",
    "            data_stm_random = correct_midline_artifact(data_stm_random,\n",
    "                                                      midline_filter)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # compute random trial time courses\n",
    "        _, trial_courses_random = sum_pixels_in_registered_mask(data_stm_random, maskwarp)\n",
    "        data_stm_random = None\n",
    "        \n",
    "        #####################################################################\n",
    "        ######## REMOVE INFINITIES, NANS ETC FROM DATA ######################\n",
    "        #####################################################################\n",
    "        if trial_courses.shape[0]==0 or trial_courses_random.shape[0]==0:\n",
    "            return np.zeros((0), 'float32'), np.zeros((0), 'float32') \n",
    "\n",
    "        #print (trial_courses.shape, trial_courses_random.shape)\n",
    "        trial_courses_fixed, trial_courses_random_fixed = fix_trials(trial_courses, trial_courses_random)\n",
    "\n",
    "        np.save(fname_04[:-4]+ \"_area_ids.npy\", area_ids)\n",
    "        np.save(fname_04, trial_courses_fixed)\n",
    "        #print (\"Saved DFF for triggered data: \", fname_04, trial_courses_fixed.shape)\n",
    "\n",
    "        #offset = DLC_offset\n",
    "        np.save(fname_random, trial_courses_random_fixed)\n",
    "        #print (\"Saved DFF for random data: \", trial_courses_random_fixed.shape)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        trial_courses_fixed = np.load(fname_04)\n",
    "\n",
    "        trial_courses_random_fixed = np.load(fname_random)\n",
    "\n",
    "        \n",
    "    return trial_courses_fixed, trial_courses_random_fixed\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid_function(x, a, b):\n",
    "\n",
    "    return np.clip(a*(np.ma.log(x) - np.ma.log(1 - x))+b, 0, 1)      #Compute sigmoid and cut off values below 0 and above 1\n",
    "    \n",
    "    \n",
    "def mangle(width, x, img_temp, maxval, power, val999):\n",
    "    \n",
    "    mu = 0 #Select approximate midline as centre of gaussian\n",
    "    sig = width\n",
    "    \n",
    "    a = .005       #The steepness of the sigmoid function\n",
    "    b = val999        #% of maxval to cutoff\n",
    "\n",
    "\n",
    "    #Normalize img_temp for sigmoid to work properly\n",
    "    #img_temp_norm = (img_temp-np.min(img_temp))/(np.max(img_temp) - np.min(img_temp))\n",
    "    img_temp_norm = (img_temp-np.min(img_temp))/(np.max(img_temp) - np.min(img_temp))\n",
    "\n",
    "\n",
    "    #Original root function\n",
    "    #return -np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.))) * (abs(pix_val/maxval)**(1./power))\n",
    "    return -np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.))) * sigmoid_function(img_temp_norm, a, b)\n",
    "\n",
    "\n",
    "# FUNCTION TO MASK\n",
    "def motion_mask_parallel(img_temp, maxval, val999, width, power):\n",
    "    '''Parallel computation of mask\n",
    "    '''\n",
    "   \n",
    "    y_array = []\n",
    "    for x in range(len(img_temp)):\n",
    "        y_array.append(np.arange(0,len(img_temp), 1))\n",
    "        \n",
    "    y_array = np.vstack(y_array)\n",
    "    motion_mask = img_temp*mangle(width, np.abs(64-y_array), img_temp, maxval, power, val999)\n",
    "    \n",
    "                   \n",
    "    motion_mask = (motion_mask-np.min(motion_mask))/(np.max(motion_mask)-np.min(motion_mask))\n",
    "\n",
    "    idx = np.where(motion_mask==0)\n",
    "    motion_mask[idx]=1\n",
    "    \n",
    "    #motion_mask = motion_mask * img_temp\n",
    "        \n",
    "    return motion_mask\n",
    "\n",
    "def save_npz_data(names, \n",
    "                  lockout_window,\n",
    "                  n_sec_window,\n",
    "                  feature_name,\n",
    "                  selected_sessions_animal, \n",
    "                  best_sessions_animal):\n",
    "\n",
    "    #feature_name = 'code_04'\n",
    "    #lockout_window = 10\n",
    "    #n_sec_window = 10\n",
    "\n",
    "    for name in names:\n",
    "\n",
    "        # \n",
    "        fname_out = '/home/cat/'+name+'.npz'\n",
    "\n",
    "        # \n",
    "        data_04_list = []\n",
    "        data_04_random_list = []\n",
    "        data_04_lockout_list = []\n",
    "        data_04_lockout_random_list = []\n",
    "\n",
    "        session_list = []\n",
    "        ctr_list = []\n",
    "\n",
    "\n",
    "        root_dir = '/media/cat/4TBSSD/yuki/'+name\n",
    "\n",
    "        temp_recs = np.load(root_dir+'/tif_files.npy')\n",
    "        recordings =[]\n",
    "        for k in range(len(temp_recs)):\n",
    "            try:\n",
    "                recordings.append(str(os.path.split(temp_recs[k])[1][:-4], \"utf-8\"))\n",
    "            except:\n",
    "                recordings.append(os.path.split(temp_recs[k])[1][:-4])\n",
    "\n",
    "        print (\"PROCESSING: \", name)\n",
    "\n",
    "        print (\"rec id,      rec name,           all rewarded trials,   \"+\n",
    "               str(n_sec_window) + \" sec lockout rewarded trials (*** good sessions; ####### best 3 sessions\")\n",
    "        for ctr,recording in enumerate(recordings):\n",
    "\n",
    "            try: \n",
    "                (data_04, data_04_random, data_04_lockout, data_04_lockout_random) = load_trial_courses_ROI_code04_trigger(\n",
    "                                                                                                      recording,\n",
    "                                                                                                      root_dir,\n",
    "                                                                                                      feature_name,\n",
    "                                                                                                      lockout_window,\n",
    "                                                                                                      n_sec_window)\n",
    "                data_04_list.append(data_04)\n",
    "                data_04_random_list.append(data_04_random)\n",
    "                data_04_lockout_list.append(data_04_lockout)\n",
    "                data_04_lockout_random_list.append(data_04_lockout_random)\n",
    "\n",
    "                session_list.append(recording)\n",
    "                ctr_list.append(ctr)\n",
    "\n",
    "            except:\n",
    "                data_04 = np.zeros((0),'float32')\n",
    "                data_04_random = data_04\n",
    "                data_04_lockout = data_04\n",
    "                data_04_lockout_random = data_04\n",
    "\n",
    "                data_04_list.append(data_04)\n",
    "                data_04_random_list.append(data_04)\n",
    "                data_04_lockout_list.append(data_04)\n",
    "                data_04_lockout_random_list.append(data_04)\n",
    "\n",
    "                session_list.append(recording)\n",
    "                ctr_list.append(ctr)\n",
    "\n",
    "            # MAKE PRINTOUT TABLE\n",
    "            prefix = '       '\n",
    "            if ctr in selected_sessions_animal:\n",
    "                if ctr in best_sessions_animal:\n",
    "                    prefix=\"#######\"\n",
    "                else:\n",
    "                    prefix='    ***'\n",
    "\n",
    "            print (prefix,ctr, \"     \", recording,\"    \", data_04.shape, \"        \", data_04_lockout.shape)\n",
    "\n",
    "        np.savez(fname_out,\n",
    "                 data_04 = data_04_list, \n",
    "                 data_04_random = data_04_random_list, \n",
    "                 data_04_lockout = data_04_lockout_list,\n",
    "                 data_04_lockout_random= data_04_lockout_random_list,\n",
    "                 session_list = session_list, \n",
    "                 ctr_list = ctr_list,\n",
    "                 selected_sessions = selected_sessions_animal,\n",
    "                 best_sessions = best_sessions_animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # COMPUTE DFF + TRIAL COURSES ROI - OLD VERSION\n",
    "# names = ['IA1','IA2','IA3','IJ1','IJ2','AR4','AQ2']\n",
    "# #names = ['AQ2']\n",
    "\n",
    "# for name in names:\n",
    "#     root_dir = '/media/cat/4TBSSD/yuki/'+name\n",
    "#     recordings = np.loadtxt(root_dir + '/'+name+'.txt',dtype='str')\n",
    "    \n",
    "#     print (\"PROCESSING: \", name)\n",
    "    \n",
    "#     if False:\n",
    "#         import parmap\n",
    "#         parmap.map(compute_trial_courses_ROI, recordings, root_dir, \n",
    "#                    pm_processes=4,\n",
    "#                    pm_pbar=True)\n",
    "\n",
    "#     else:\n",
    "#         from tqdm import tqdm\n",
    "#         for recording in tqdm(recordings):\n",
    "#             compute_trial_courses_ROI(recording, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING:  IA2\n",
      "recording:  IA2pm_Feb1_30Hz\n",
      "recording:  IA2pm_Feb2_30Hz\n",
      "recording:  IA2pm_Feb3_30Hz\n",
      "recording:  IA2pm_Feb4_30Hz\n",
      "recording:  IA2pm_Feb5_30Hz\n",
      "FEATURE NAMES:  ['left_paw' 'right_paw' 'nose' 'jaw' 'right_ear' 'tongue' 'lever'\n",
      " 'grooming']\n",
      "Shifting [ca]  4.104\n",
      "FEATURE NAMES:  ['left_paw' 'right_paw' 'nose' 'jaw' 'right_ear' 'tongue' 'lever'\n",
      " 'grooming']\n",
      "Shifting [ca]  4.104\n",
      "FEATURE NAMES:  ['left_paw' 'right_paw' 'nose' 'jaw' 'right_ear' 'tongue' 'lever'\n",
      " 'grooming']\n",
      "Shifting [ca]  4.104\n",
      "FEATURE NAMES:  ['left_paw' 'right_paw' 'nose' 'jaw' 'right_ear' 'tongue' 'lever'\n",
      " 'grooming']\n",
      "Shifting [ca]  4.104\n",
      "FEATURE NAMES:  ['left_paw' 'right_paw' 'nose' 'jaw' 'right_ear' 'tongue' 'lever'\n",
      " 'grooming']\n",
      "Shifting [ca]  4.104\n",
      "data_stm is None IA2pm_Feb5_30Hz\n",
      "FEATURE NAMES:  ['left_paw' 'right_paw' 'nose' 'jaw' 'right_ear' 'tongue' 'lever'\n",
      " 'grooming']\n",
      "Shifting [ca]  4.104\n",
      "FEATURE NAMES:  ['left_paw' 'right_paw' 'nose' 'jaw' 'right_ear' 'tongue' 'lever'\n",
      " 'grooming']\n",
      "Shifting [ca]  4.104\n",
      "data_stm is None IA2pm_Feb5_30Hz\n",
      "FEATURE NAMES:  ['left_paw' 'right_paw' 'nose' 'jaw' 'right_ear' 'tongue' 'lever'\n",
      " 'grooming']\n",
      "Could not find feature:  grooming\n",
      "Shifting [ca]  4.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 44/44 [01:01<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_stm is None IA2pm_Feb5_30Hz\n",
      "recording:  IA2pm_Feb9_30Hz\n",
      "recording:  IA2pm_Feb10_30Hz\n",
      "recording:  IA2pm_Feb11_30Hz\n",
      "recording:  IA2pm_Feb12_30Hz\n",
      "recording:  IA2pm_Feb15_30Hz\n",
      "recording:  IA2pm_Feb16_30Hz\n",
      "recording:  IA2pm_Feb17_30Hz\n",
      "recording:  IA2pm_Feb18_30Hz\n",
      "recording:  IA2pm_Feb19_30Hz\n",
      "recording:  IA2pm_Feb22_30Hz\n",
      "recording:  IA2pm_Feb23_30Hz\n",
      "recording:  IA2pm_Feb24_30Hz\n",
      "recording:  IA2pm_Feb25_30Hz\n",
      "recording:  IA2pm_Feb26_30Hz\n",
      "recording:  IA2pm_Feb29_30Hz\n",
      "recording:  IA2pm_Mar1_30Hz\n",
      "recording:  IA2pm_Mar2_30Hz\n",
      "recording:  IA2pm_Mar3_30Hz\n",
      "recording:  IA2am_Mar4_30Hz\n",
      "recording:  IA2am_Mar7_30Hz\n",
      "recording:  IA2pm_Mar8_30Hz\n",
      "recording:  IA2am_Mar9_30Hz\n",
      "recording:  IA2am_Mar10_30Hz\n",
      "recording:  IA2am_Mar11_30Hz\n",
      "recording:  IA2pm_Mar14_30Hz\n",
      "recording:  IA2am_Mar15_30Hz\n",
      "recording:  IA2pm_Mar16_30Hz\n",
      "recording:  IA2pm_Mar17_30Hz\n",
      "recording:  IA2pm_Mar18_30Hz\n",
      "recording:  IA2pm_Mar21_30Hz\n",
      "recording:  IA2pm_Mar23_30Hz\n",
      "recording:  IA2pm_Mar24_30Hz\n",
      "recording:  IA2pm_Mar29_30Hz\n",
      "recording:  IA2pm_Mar30_30Hz\n",
      "recording:  IA2pm_Mar31_30Hz\n",
      "recording:  IA2pm_Apr1_30Hz\n",
      "recording:  IA2pm_Apr4_30Hz\n",
      "recording:  IA2pm_Apr5_30Hz\n",
      "recording:  IA2pm_Apr6_30Hz\n",
      "DONE WITH  IA2\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "##### COMPUTE ROI TRIAL COURSES - WITH & WITHOUT LOCKOUT #########\n",
    "##################################################################\n",
    "'''  Compute calcium activity in ROIs selected (35) for \n",
    "    lever pull actiivty\n",
    "'''\n",
    "\n",
    "# select animal names\n",
    "#names = ['IA1','IA2','IA3','IJ1','IJ2','AR4','AQ2']\n",
    "names = ['IA2']\n",
    "\n",
    "session = 'Feb5'\n",
    "\n",
    "from tqdm import tqdm\n",
    "feature_names = ['left_paw','right_paw', 'nose', 'jaw', 'right_ear', 'tongue', 'lever', 'grooming']\n",
    "midline_filter_flag = True\n",
    "\n",
    "# window to compute\n",
    "total_window = 10.0               # compute DFF window\n",
    "lockout_window = 4.0\n",
    "n_sec_window = total_window\n",
    "\n",
    "#\n",
    "compute_all_DFF_flag = False        # these flag computes DFF for all possible body movements; MEMORY CRASH\n",
    "compute_lockout_DFF_flag = True    # this flag computes DFF only for initiations of behavior not all movements; \n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "# \n",
    "recompute = False  # overwrite previously generated data\n",
    "\n",
    "for name in names:\n",
    "    root_dir = '/media/cat/4TBSSD/yuki/'+name\n",
    "    #recordings = np.loadtxt(root_dir + '/'+name+'.txt',dtype='str')\n",
    "    \n",
    "    temp_recs = np.load(root_dir+'/tif_files.npy')\n",
    "    recordings =[]\n",
    "    for k in range(len(temp_recs)):\n",
    "        try:\n",
    "            recordings.append(str(os.path.split(temp_recs[k])[1][:-4], \"utf-8\"))\n",
    "        except:\n",
    "            recordings.append(os.path.split(temp_recs[k])[1][:-4])\n",
    "    \n",
    "    print (\"PROCESSING: \", name)\n",
    "    \n",
    "    if False:\n",
    "        import parmap\n",
    "        parmap.map(compute_trial_courses_ROI_code04_trigger, \n",
    "                       recordings,\n",
    "                       root_dir,\n",
    "                       feature_names,\n",
    "                       lockout_window,\n",
    "                       n_sec_window,\n",
    "                       compute_all_DFF_flag,\n",
    "                        compute_lockout_DFF_flag,\n",
    "                       recompute,\n",
    "                       midline_filter_flag,\n",
    "                       total_window,\n",
    "                       pm_processes=2,\n",
    "                       pm_pbar=True)\n",
    "    else:\n",
    "        res = []\n",
    "        for recording in tqdm(recordings):\n",
    "            print (\"recording: \", recording)\n",
    "            \n",
    "            if session in recording:\n",
    "                compute_trial_courses_ROI_code04_trigger(recording,\n",
    "                                                        root_dir,\n",
    "                                                        feature_names,\n",
    "                                                        lockout_window,\n",
    "                                                        n_sec_window,\n",
    "                                                        compute_all_DFF_flag,\n",
    "                                                        compute_lockout_DFF_flag,\n",
    "                                                        recompute,\n",
    "                                                        midline_filter_flag,\n",
    "                                                        total_window\n",
    "                                                        )\n",
    "    print (\"DONE WITH \", name)\n",
    "    print ('')\n",
    "    print ('')\n",
    "    print ('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING:  AQ2\n",
      "rec id,      rec name,           all rewarded trials,   15 sec lockout rewarded trials (*** good sessions; ####### best 3 sessions\n",
      "        0       AQ2am_Dec9_30Hz      (0,)          (0,)\n",
      "        1       AQ2am_Dec10_30Hz      (0,)          (0,)\n",
      "        2       AQ2pm_Dec10_30Hz      (0,)          (0,)\n",
      "        3       AQ2am_Dec11_30Hz      (7, 35, 901)          (7, 35, 901)\n",
      "        4       AQ2pm_Dec14_30Hz      (10, 35, 901)          (8, 35, 901)\n",
      "        5       AQ2am_Dec14_30Hz      (0,)          (0,)\n",
      "        6       AQ2pm_Dec16_30Hz      (27, 35, 901)          (20, 35, 901)\n",
      "        7       AQ2am_Dec17_30Hz      (21, 35, 901)          (12, 35, 901)\n",
      "        8       AQ2pm_Dec17_30Hz      (5, 35, 901)          (5, 35, 901)\n",
      "        9       AQ2am_Dec18_30Hz      (7, 35, 901)          (7, 35, 901)\n",
      "        10       AQ2pm_Dec18_30Hz      (4, 35, 901)          (4, 35, 901)\n",
      "        11       AQ2am_Dec21_30Hz      (2, 35, 901)          (2, 35, 901)\n",
      "        12       AQ2am_Dec22_30Hz      (0,)          (0,)\n",
      "        13       AQ2am_Dec23_30Hz      (0,)          (0,)\n",
      "        14       AQ2am_Dec28_30Hz      (24, 35, 901)          (8, 35, 901)\n",
      "        15       AQ2am_Dec29_30Hz      (33, 35, 901)          (25, 35, 901)\n",
      "        16       AQ2am_Dec30_30Hz      (0,)          (0,)\n",
      "        17       AQ2am_Dec31_30Hz      (65, 35, 901)          (38, 35, 901)\n",
      "        18       AQ2am_Jan4_30Hz      (52, 35, 901)          (36, 35, 901)\n",
      "        19       AQ2am_Jan5_30Hz      (51, 35, 901)          (27, 35, 901)\n",
      "        20       AQ2am_Jan6_30Hz      (59, 35, 901)          (31, 35, 901)\n",
      "        21       AQ2am_Jan7_30Hz      (4, 35, 901)          (2, 35, 901)\n",
      "        22       AQ2am_Jan8_30Hz      (27, 35, 901)          (18, 35, 901)\n",
      "        23       AQ2pm_Jan11_30Hz      (17, 35, 901)          (13, 35, 901)\n",
      "        24       AQ2am_Jan11_30Hz      (0,)          (0,)\n",
      "        25       AQ2pm_Jan12_30Hz      (2, 35, 901)          (2, 35, 901)\n",
      "        26       AQ2am_Jan12_30Hz      (0,)          (0,)\n",
      "        27       AQ2pm_Jan13_30Hz      (37, 35, 901)          (24, 35, 901)\n",
      "        28       AQ2am_Jan13_30Hz      (54, 35, 901)          (32, 35, 901)\n",
      "        29       AQ2pm_Jan14_30Hz      (37, 35, 901)          (27, 35, 901)\n",
      "        30       AQ2am_Jan14_30Hz      (42, 35, 901)          (25, 35, 901)\n",
      "        31       AQ2am_Jan15_30Hz      (26, 35, 901)          (20, 35, 901)\n",
      "####### 32       AQ2pm_Jan15_30Hz      (70, 35, 901)          (27, 35, 901)\n",
      "        33       AQ2pm_Jan18_30Hz      (0,)          (0,)\n",
      "        34       AQ2am_Jan18_30Hz      (12, 35, 901)          (9, 35, 901)\n",
      "        35       AQ2am_Jan19_30Hz      (0,)          (0,)\n",
      "        36       AQ2pm_Jan19_30Hz      (0,)          (0,)\n",
      "        37       AQ2pm_Jan20_30Hz      (0,)          (0,)\n",
      "        38       AQ2am_Jan20_30Hz      (2, 35, 901)          (2, 35, 901)\n",
      "        39       AQ2pm_Jan21_30Hz      (0,)          (0,)\n",
      "        40       AQ2am_Jan21_30Hz      (0,)          (0,)\n",
      "        41       AQ2pm_Jan22_30Hz      (2, 35, 901)          (2, 35, 901)\n",
      "        42       AQ2am_Jan22_30Hz      (4, 35, 901)          (4, 35, 901)\n",
      "        43       AQ2am_Jan25_30Hz      (0,)          (0,)\n",
      "        44       AQ2pm_Jan25_30Hz      (0,)          (0,)\n",
      "        45       AQ2pm_Jan26_30Hz      (0,)          (0,)\n",
      "        46       AQ2am_Jan26_30Hz      (0,)          (0,)\n",
      "        47       AQ2am_Jan27_30Hz      (3, 35, 901)          (3, 35, 901)\n",
      "        48       AQ2pm_Jan27_30Hz      (55, 35, 901)          (28, 35, 901)\n",
      "        49       AQ2am_Jan28_30Hz      (46, 35, 901)          (34, 35, 901)\n",
      "    *** 50       AQ2pm_Jan28_30Hz      (60, 35, 901)          (33, 35, 901)\n",
      "        51       AQ2am_Jan29_30Hz      (41, 35, 901)          (31, 35, 901)\n",
      "        52       AQ2pm_Jan29_30Hz      (50, 35, 901)          (21, 35, 901)\n",
      "    *** 53       AQ2am_Feb2_30Hz      (67, 35, 901)          (26, 35, 901)\n",
      "    *** 54       AQ2am_Feb3_30Hz      (78, 35, 901)          (27, 35, 901)\n",
      "        55       AQ2am_Feb4_30Hz      (21, 35, 901)          (21, 35, 901)\n",
      "    *** 56       AQ2am_Feb5_30Hz      (74, 35, 901)          (32, 35, 901)\n",
      "    *** 57       AQ2am_Feb9_30Hz      (91, 35, 901)          (30, 35, 901)\n",
      "####### 58       AQ2am_Feb10_30Hz      (93, 35, 901)          (29, 35, 901)\n",
      "    *** 59       AQ2am_Feb11_30Hz      (131, 35, 901)          (23, 35, 901)\n",
      "        60       AQ2am_Feb12_30Hz      (183, 35, 901)          (12, 35, 901)\n",
      "        61       AQ2am_Feb15_30Hz      (157, 35, 901)          (9, 35, 901)\n",
      "        62       AQ2am_Feb16_30Hz      (145, 35, 901)          (17, 35, 901)\n",
      "    *** 63       AQ2am_Feb17_30Hz      (104, 35, 901)          (25, 35, 901)\n",
      "    *** 64       AQ2am_Feb18_30Hz      (156, 35, 901)          (12, 35, 901)\n",
      "    *** 65       AQ2am_Feb19_30Hz      (96, 35, 901)          (24, 35, 901)\n",
      "    *** 66       AQ2am_Feb22_30Hz      (144, 35, 901)          (20, 35, 901)\n",
      "    *** 67       AQ2am_Feb23_30Hz      (120, 35, 901)          (21, 35, 901)\n",
      "        68       AQ2am_Feb25_30Hz      (0,)          (0,)\n",
      "        69       AQ2am_Feb26_30Hz      (92, 35, 901)          (16, 35, 901)\n",
      "    *** 70       AQ2am_Feb29_30Hz      (90, 35, 901)          (27, 35, 901)\n",
      "    *** 71       AQ2am_Mar1_30Hz      (125, 35, 901)          (21, 35, 901)\n",
      "    *** 72       AQ2am_Mar2_30Hz      (58, 35, 901)          (19, 35, 901)\n",
      "    *** 73       AQ2am_Mar3_30Hz      (129, 35, 901)          (17, 35, 901)\n",
      "    *** 74       AQ2pm_Mar7_Day3_30Hz      (109, 35, 901)          (23, 35, 901)\n",
      "        75       AQ2pm_Mar9_Day5_30Hz      (70, 35, 901)          (18, 35, 901)\n",
      "        76       AQ2pm_Mar11_Day7_30Hz      (99, 35, 901)          (19, 35, 901)\n",
      "    *** 77       AQ2am_Mar14_Week2_30Hz      (103, 35, 901)          (19, 35, 901)\n",
      "    *** 78       AQ2pm_Mar15_Week2_30Hz      (143, 35, 901)          (17, 35, 901)\n",
      "    *** 79       AQ2am_Mar16_Week2_30Hz      (122, 35, 901)          (17, 35, 901)\n",
      "    *** 80       AQ2am_Mar17_Week2_30Hz      (104, 35, 901)          (34, 35, 901)\n",
      "    *** 81       AQ2am_Mar18_Week2_30Hz      (139, 35, 901)          (23, 35, 901)\n",
      "        82       AQ2am_Mar21_Week3_30Hz      (47, 35, 901)          (26, 35, 901)\n",
      "    *** 83       AQ2am_Mar22_Week3_30Hz      (64, 35, 901)          (39, 35, 901)\n",
      "    *** 84       AQ2am_Mar23_Week3_30Hz      (84, 35, 901)          (23, 35, 901)\n",
      "    *** 85       AQ2am_Mar24_Week3_30Hz      (124, 35, 901)          (22, 35, 901)\n",
      "    *** 86       AQ2am_Mar29_Week4_30Hz      (91, 35, 901)          (32, 35, 901)\n",
      "    *** 87       AQ2am_Mar30_Week4_30Hz      (147, 35, 901)          (17, 35, 901)\n",
      "    *** 88       AQ2am_Mar31_Week4_30Hz      (114, 35, 901)          (31, 35, 901)\n",
      "    *** 89       AQ2am_Apr1_Week4_30Hz      (137, 35, 901)          (26, 35, 901)\n",
      "    *** 90       AQ2am_Apr4_Week5_30Hz      (127, 35, 901)          (19, 35, 901)\n",
      "####### 91       AQ2am_Apr5_Week5_30Hz      (100, 35, 901)          (31, 35, 901)\n",
      "    *** 92       AQ2am_Apr6_Week5_30Hz      (117, 35, 901)          (19, 35, 901)\n",
      "    *** 93       AQ2am_Apr7_Week5_30Hz      (93, 35, 901)          (33, 35, 901)\n",
      "    *** 94       AQ2am_Apr8_Week5_30Hz      (104, 35, 901)          (21, 35, 901)\n",
      "    *** 95       AQ2am_Apr11_Week6_30Hz      (142, 35, 901)          (18, 35, 901)\n",
      "    *** 96       AQ2am_Apr12_Week6_30Hz      (94, 35, 901)          (33, 35, 901)\n",
      "    *** 97       AQ2am_Apr13_Week6_30Hz      (105, 35, 901)          (27, 35, 901)\n",
      "    *** 98       AQ2am_Apr14_Week6_30Hz      (98, 35, 901)          (30, 35, 901)\n",
      "    *** 99       AQ2am_Apr15_Week6_30Hz      (83, 35, 901)          (30, 35, 901)\n",
      "    *** 100       AQ2am_Apr18_Week7_30Hz      (77, 35, 901)          (39, 35, 901)\n",
      "    *** 101       AQ2am_Apr19_Week7_30Hz      (70, 35, 901)          (36, 35, 901)\n",
      "    *** 102       AQ2am_Apr20_Week7_30Hz      (69, 35, 901)          (35, 35, 901)\n",
      "    *** 103       AQ2am_Apr21_Week7_30Hz      (52, 35, 901)          (31, 35, 901)\n",
      "    *** 104       AQ2am_Apr22_Week7_30Hz      (121, 35, 901)          (25, 35, 901)\n",
      "    *** 105       AQ2am_Apr25_Week8_30Hz      (114, 35, 901)          (24, 35, 901)\n",
      "    *** 106       AQ2am_Apr26_Week8_30Hz      (112, 35, 901)          (26, 35, 901)\n",
      "    *** 107       AQ2am_Apr27_Week8_30Hz      (138, 35, 901)          (13, 35, 901)\n",
      "    *** 108       AQ2am_Apr28_Week8_30Hz      (86, 35, 901)          (36, 35, 901)\n",
      "    *** 109       AQ2am_Apr29_Week8_30Hz      (82, 35, 901)          (35, 35, 901)\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#### MAKE TIME ORDERED .NZP FILES ##################\n",
    "#########################################################\n",
    "\n",
    "# MANUALLY FIND WHICH SESSIONS HAVE LARGE DIFFERENCE in BEWEEN WITH /WITHOUT PULL OVERLAP IN 10SEC WINDOW\n",
    "# AQ2\n",
    "selected_sessions_AQ2 = [32,50,53,54,56,57,58,59,63,64,65,66,67,70,71,72,73,74,77,78,79,80,81]\n",
    "selected_sessions_AQ2 = np.append(selected_sessions_AQ2,np.arange(83,110))\n",
    "best_sessions_AQ2 = [32,58,91]\n",
    "\n",
    "# IA1\n",
    "selected_sessions_IA1 = [2,10,11,13,15,29]\n",
    "best_sessions_IA1 = [13,15,29]\n",
    "\n",
    "# IA2\n",
    "selected_sessions_IA2 = [3,4,13,21,28,29,30,31,32,35,40,43]\n",
    "best_sessions_IA2 = [3,29,40]\n",
    "\n",
    "# IA3\n",
    "selected_sessions_IA3 = [1,2,7,17,21,25,31,32,33,34,35,36,37,38,39,40,41,42,43]\n",
    "best_sessions_IA3 = [2,34,43]\n",
    "\n",
    "# IJ1\n",
    "selected_sessions_IJ1 = [6,7,8,10,14,18,20,21,22,38]\n",
    "best_sessions_IJ1 = [14,22,38]\n",
    "\n",
    "# IJ2\n",
    "selected_sessions_IJ2 = [2,17,18,19,20,26,33,37,39,40,43]\n",
    "best_sessions_IJ2 = [20,33,40]\n",
    "\n",
    "# AR4\n",
    "selected_sessions_AR4 = [6,12,14,23,26,27,28,30,31,32]\n",
    "best_sessions_AR4 = [6,23,30]\n",
    "\n",
    "\n",
    "####################################################\n",
    "# SELECT A RECORDING TO COMBINE\n",
    "# CHECK ALL VS. LOCKOUT DATA\n",
    "#names = ['IA1','IA2','IA3','IJ1','IJ2','AR4','AQ2']\n",
    "names = ['AQ2']\n",
    "\n",
    "selected_sessions_animal = selected_sessions_AQ2\n",
    "best_sessions_animal = best_sessions_AQ2\n",
    "\n",
    "save_npz_data(names, \n",
    "              lockout_window,\n",
    "              n_sec_window,\n",
    "              feature_name,\n",
    "              selected_sessions_animal, \n",
    "              best_sessions_animal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING:  AQ2\n",
      "rec id,      rec name,           all rewarded trials,   10sec lockout rewarded trials\n",
      "*** 3       AQ2am_Dec11_30Hz      (7, 35, 601)          (7, 35, 601)\n",
      "    4       AQ2pm_Dec14_30Hz      (10, 35, 601)          (9, 35, 601)\n",
      "    6       AQ2pm_Dec16_30Hz      (27, 35, 601)          (22, 35, 601)\n",
      "    7       AQ2am_Dec17_30Hz      (21, 35, 601)          (15, 35, 601)\n",
      "    8       AQ2pm_Dec17_30Hz      (5, 35, 601)          (5, 35, 601)\n",
      "    9       AQ2am_Dec18_30Hz      (7, 35, 601)          (7, 35, 601)\n",
      "    10       AQ2pm_Dec18_30Hz      (5, 35, 601)          (5, 35, 601)\n",
      "    11       AQ2am_Dec21_30Hz      (2, 35, 601)          (2, 35, 601)\n",
      "    14       AQ2am_Dec28_30Hz      (24, 35, 601)          (13, 35, 601)\n",
      "    15       AQ2am_Dec29_30Hz      (33, 35, 601)          (27, 35, 601)\n",
      "    17       AQ2am_Dec31_30Hz      (65, 35, 601)          (51, 35, 601)\n",
      "    18       AQ2am_Jan4_30Hz      (52, 35, 601)          (42, 35, 601)\n",
      "    19       AQ2am_Jan5_30Hz      (52, 35, 601)          (39, 35, 601)\n",
      "    20       AQ2am_Jan6_30Hz      (59, 35, 601)          (49, 35, 601)\n",
      "    21       AQ2am_Jan7_30Hz      (4, 35, 601)          (4, 35, 601)\n",
      "    22       AQ2am_Jan8_30Hz      (27, 35, 601)          (22, 35, 601)\n",
      "    23       AQ2pm_Jan11_30Hz      (17, 35, 601)          (16, 35, 601)\n",
      "    25       AQ2pm_Jan12_30Hz      (2, 35, 601)          (2, 35, 601)\n",
      "    27       AQ2pm_Jan13_30Hz      (37, 35, 601)          (31, 35, 601)\n",
      "    28       AQ2am_Jan13_30Hz      (55, 35, 601)          (43, 35, 601)\n",
      "    29       AQ2pm_Jan14_30Hz      (37, 35, 601)          (34, 35, 601)\n",
      "*** 30       AQ2am_Jan14_30Hz      (43, 35, 601)          (37, 35, 601)\n",
      "    31       AQ2am_Jan15_30Hz      (26, 35, 601)          (23, 35, 601)\n",
      "    32       AQ2pm_Jan15_30Hz      (70, 35, 601)          (41, 35, 601)\n",
      "    34       AQ2am_Jan18_30Hz      (13, 35, 601)          (10, 35, 601)\n",
      "    38       AQ2am_Jan20_30Hz      (2, 35, 601)          (2, 35, 601)\n",
      "    41       AQ2pm_Jan22_30Hz      (3, 35, 601)          (3, 35, 601)\n",
      "    42       AQ2am_Jan22_30Hz      (4, 35, 601)          (4, 35, 601)\n",
      "    47       AQ2am_Jan27_30Hz      (3, 35, 601)          (3, 35, 601)\n",
      "    48       AQ2pm_Jan27_30Hz      (55, 35, 601)          (35, 35, 601)\n",
      "    49       AQ2am_Jan28_30Hz      (46, 35, 601)          (43, 35, 601)\n",
      "*** 50       AQ2pm_Jan28_30Hz      (61, 35, 601)          (47, 35, 601)\n",
      "    51       AQ2am_Jan29_30Hz      (41, 35, 601)          (34, 35, 601)\n",
      "    52       AQ2pm_Jan29_30Hz      (50, 35, 601)          (27, 35, 601)\n",
      "    53       AQ2am_Feb2_30Hz      (68, 35, 601)          (46, 35, 601)\n",
      "    54       AQ2am_Feb3_30Hz      (79, 35, 601)          (52, 35, 601)\n",
      "    55       AQ2am_Feb4_30Hz      (21, 35, 601)          (21, 35, 601)\n",
      "    56       AQ2am_Feb5_30Hz      (74, 35, 601)          (52, 35, 601)\n",
      "    57       AQ2am_Feb9_30Hz      (91, 35, 601)          (47, 35, 601)\n",
      "    58       AQ2am_Feb10_30Hz      (93, 35, 601)          (54, 35, 601)\n",
      "    59       AQ2am_Feb11_30Hz      (131, 35, 601)          (44, 35, 601)\n",
      "    60       AQ2am_Feb12_30Hz      (184, 35, 601)          (19, 35, 601)\n",
      "    61       AQ2am_Feb15_30Hz      (158, 35, 601)          (19, 35, 601)\n",
      "    62       AQ2am_Feb16_30Hz      (145, 35, 601)          (32, 35, 601)\n",
      "    63       AQ2am_Feb17_30Hz      (104, 35, 601)          (54, 35, 601)\n",
      "    64       AQ2am_Feb18_30Hz      (156, 35, 601)          (35, 35, 601)\n",
      "    65       AQ2am_Feb19_30Hz      (96, 35, 601)          (41, 35, 601)\n",
      "    66       AQ2am_Feb22_30Hz      (145, 35, 601)          (39, 35, 601)\n",
      "    67       AQ2am_Feb23_30Hz      (121, 35, 601)          (51, 35, 601)\n",
      "    69       AQ2am_Feb26_30Hz      (92, 35, 601)          (29, 35, 601)\n",
      "    70       AQ2am_Feb29_30Hz      (91, 35, 601)          (44, 35, 601)\n",
      "    71       AQ2am_Mar1_30Hz      (127, 35, 601)          (37, 35, 601)\n",
      "    72       AQ2am_Mar2_30Hz      (58, 35, 601)          (36, 35, 601)\n",
      "    73       AQ2am_Mar3_30Hz      (131, 35, 601)          (38, 35, 601)\n",
      "    74       AQ2pm_Mar7_Day3_30Hz      (110, 35, 601)          (35, 35, 601)\n",
      "    75       AQ2pm_Mar9_Day5_30Hz      (71, 35, 601)          (27, 35, 601)\n",
      "    76       AQ2pm_Mar11_Day7_30Hz      (99, 35, 601)          (28, 35, 601)\n",
      "    77       AQ2am_Mar14_Week2_30Hz      (104, 35, 601)          (42, 35, 601)\n",
      "    78       AQ2pm_Mar15_Week2_30Hz      (144, 35, 601)          (36, 35, 601)\n",
      "    79       AQ2am_Mar16_Week2_30Hz      (122, 35, 601)          (37, 35, 601)\n",
      "    80       AQ2am_Mar17_Week2_30Hz      (104, 35, 601)          (50, 35, 601)\n",
      "    81       AQ2am_Mar18_Week2_30Hz      (140, 35, 601)          (45, 35, 601)\n",
      "    82       AQ2am_Mar21_Week3_30Hz      (48, 35, 601)          (32, 35, 601)\n",
      "    83       AQ2am_Mar22_Week3_30Hz      (64, 35, 601)          (47, 35, 601)\n",
      "    84       AQ2am_Mar23_Week3_30Hz      (85, 35, 601)          (42, 35, 601)\n",
      "    85       AQ2am_Mar24_Week3_30Hz      (125, 35, 601)          (44, 35, 601)\n",
      "    86       AQ2am_Mar29_Week4_30Hz      (91, 35, 601)          (47, 35, 601)\n",
      "    87       AQ2am_Mar30_Week4_30Hz      (149, 35, 601)          (43, 35, 601)\n",
      "    88       AQ2am_Mar31_Week4_30Hz      (116, 35, 601)          (45, 35, 601)\n",
      "    89       AQ2am_Apr1_Week4_30Hz      (138, 35, 601)          (44, 35, 601)\n",
      "    90       AQ2am_Apr4_Week5_30Hz      (127, 35, 601)          (48, 35, 601)\n",
      "    91       AQ2am_Apr5_Week5_30Hz      (100, 35, 601)          (56, 35, 601)\n",
      "    92       AQ2am_Apr6_Week5_30Hz      (118, 35, 601)          (44, 35, 601)\n",
      "    93       AQ2am_Apr7_Week5_30Hz      (93, 35, 601)          (49, 35, 601)\n",
      "    94       AQ2am_Apr8_Week5_30Hz      (105, 35, 601)          (46, 35, 601)\n",
      "    95       AQ2am_Apr11_Week6_30Hz      (144, 35, 601)          (51, 35, 601)\n",
      "    96       AQ2am_Apr12_Week6_30Hz      (94, 35, 601)          (52, 35, 601)\n",
      "    97       AQ2am_Apr13_Week6_30Hz      (106, 35, 601)          (57, 35, 601)\n",
      "    98       AQ2am_Apr14_Week6_30Hz      (99, 35, 601)          (60, 35, 601)\n",
      "    99       AQ2am_Apr15_Week6_30Hz      (84, 35, 601)          (53, 35, 601)\n",
      "    100       AQ2am_Apr18_Week7_30Hz      (77, 35, 601)          (53, 35, 601)\n",
      "    101       AQ2am_Apr19_Week7_30Hz      (71, 35, 601)          (49, 35, 601)\n",
      "    102       AQ2am_Apr20_Week7_30Hz      (69, 35, 601)          (45, 35, 601)\n",
      "    103       AQ2am_Apr21_Week7_30Hz      (53, 35, 601)          (37, 35, 601)\n",
      "    104       AQ2am_Apr22_Week7_30Hz      (123, 35, 601)          (47, 35, 601)\n",
      "    105       AQ2am_Apr25_Week8_30Hz      (114, 35, 601)          (36, 35, 601)\n",
      "    106       AQ2am_Apr26_Week8_30Hz      (112, 35, 601)          (47, 35, 601)\n",
      "    107       AQ2am_Apr27_Week8_30Hz      (138, 35, 601)          (28, 35, 601)\n",
      "    108       AQ2am_Apr28_Week8_30Hz      (86, 35, 601)          (53, 35, 601)\n",
      "    109       AQ2am_Apr29_Week8_30Hz      (85, 35, 601)          (51, 35, 601)\n"
     ]
    }
   ],
   "source": [
    "# # CHECK ALL VS. LOCKOUT DATA\n",
    "# names = ['IA1','IA2','IA3','IJ1','IJ2','AR4','AQ2']\n",
    "# names = ['AQ2']\n",
    "\n",
    "# selected_sessions = [3, 30, 50]\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# feature_name = 'code_04'\n",
    "# lockout_window = 10\n",
    "# n_sec_window = 10\n",
    "\n",
    "# for name in names:\n",
    "#     root_dir = '/media/cat/4TBSSD/yuki/'+name\n",
    "#     #recordings = np.loadtxt(root_dir + '/'+name+'.txt',dtype='str')\n",
    "    \n",
    "#     temp_recs = np.load(root_dir+'/tif_files.npy')\n",
    "#     recordings =[]\n",
    "#     for k in range(len(temp_recs)):\n",
    "#         try:\n",
    "#             recordings.append(str(os.path.split(temp_recs[k])[1][:-4], \"utf-8\"))\n",
    "#         except:\n",
    "#             recordings.append(os.path.split(temp_recs[k])[1][:-4])\n",
    "    \n",
    "#     print (\"PROCESSING: \", name)\n",
    "    \n",
    "#     print (\"rec id,      rec name,           all rewarded trials,   10sec lockout rewarded trials\")\n",
    "#     for ctr,recording in enumerate(recordings):\n",
    "\n",
    "#         try: \n",
    "#             (data_04, data_04_random, data_04_lockout, data_04_lockout_random) = load_trial_courses_ROI_code04_trigger(\n",
    "#                                                                       recording,\n",
    "#                                                                       root_dir,\n",
    "#                                                                       feature_name,\n",
    "#                                                                       lockout_window,\n",
    "#                                                                       n_sec_window)\n",
    "#             if ctr not in selected_sessions:\n",
    "#                 print (\"   \",ctr, \"     \", recording,\"    \", data_04.shape, \"        \", data_04_lockout.shape)\n",
    "#             else:\n",
    "#                 print (\"***\", ctr, \"     \", recording,\"    \", data_04.shape, \"        \", data_04_lockout.shape)\n",
    "            \n",
    "#             #print ('')\n",
    "#         except:\n",
    "#             pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MAKE ORDERED .NZP FILES\n",
    "# # MUST INPUT a temporally ordered.txt file\n",
    "# fname_list = '/media/cat/4TBSSD/yuki/time_courses/AQ2_ordered.txt'\n",
    "# fnames = np.loadtxt(fname_list,dtype='str')\n",
    "# #print (fnames)\n",
    "\n",
    "# data_list = []\n",
    "# fnames_data_list = []\n",
    "# data_random_list = []\n",
    "# fnames_data_random_list = []\n",
    "# for fname in fnames:\n",
    "#     if '04' in fname:\n",
    "#         data_list.append(np.load(fname))\n",
    "#         fnames_data_list.append(fname)\n",
    "#     else:\n",
    "#         data_random_list.append(np.load(fname))\n",
    "#         fnames_data_random_list.append(fname)\n",
    "\n",
    "# np.savez(fname_list[:-4]+'.npz',\n",
    "#         data_04_lever_pull = data_list,\n",
    "#         data_04_lever_pull_fnames = fnames_data_list,\n",
    "#         data_random = data_random_list,\n",
    "#         data_random_fnames = fnames_data_random_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DISTRIBUTION OF SESSIONS IN EACH ANIMAL\n",
    "\n",
    "all_files = [\n",
    "'/media/cat/4TBSSD/yuki/time_courses/AR4_ordered.npz',\n",
    "'/media/cat/4TBSSD/yuki/time_courses/IA1_ordered.npz',\n",
    "'/media/cat/4TBSSD/yuki/time_courses/IA2_ordered.npz',\n",
    "'/media/cat/4TBSSD/yuki/time_courses/IA3_ordered.npz',\n",
    "'/media/cat/4TBSSD/yuki/time_courses/IJ1_ordered.npz',\n",
    "'/media/cat/4TBSSD/yuki/time_courses/IJ2_ordered.npz',\n",
    "'/media/cat/4TBSSD/yuki/time_courses/AQ2_ordered.npz'\n",
    "]\n",
    "\n",
    "tot = 0\n",
    "for ctr, file_ in enumerate(all_files):\n",
    "    temp = np.load(file_, allow_pickle=True)\n",
    "    #fnames = temp['data_04_lever_pull_fnames']\n",
    "    #print (fnames)\n",
    "    data = temp['data_04_lever_pull']\n",
    "    print (file_, \" # of sessions: \", len(data))\n",
    "    tot+=len(data)\n",
    "    ax=plt.subplot(2,4,ctr+1)\n",
    "    plt.title(os.path.split(file_)[1])\n",
    "    \n",
    "    lengths = []\n",
    "    for k in range(len(data)):\n",
    "        lengths.append(len(data[k]))\n",
    "        #print (data[k].shape)\n",
    "    y = np.histogram(lengths, np.arange(0,400,10))\n",
    "    plt.plot(y[1][:-1],y[0])\n",
    "    plt.ylabel(\"# of sessions\")\n",
    "    plt.xlabel(\"# of trials in sessions\")\n",
    "    plt.xlim(0,200)\n",
    "print (\"total: \", tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DATA\n",
    "#np.save(root_dir+\"data_random_code_\"+str(locs_selected.shape[0])+\"trials_.npy\", data_stm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35, 601)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/4TBSSD/yuki/IA2/tif_files/IA2pm_Apr6_30Hz/data_random_code_64trials_ROIs.npy')\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Oct27pm_15Hz_8x8/AR4_Oct27pm_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Oct28pm_15Hz_8x8/AR4_Oct28pm_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Oct29pm_15Hz_8x8/AR4_Oct29pm_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov3pm_15Hz_8x8/AR4_Nov3pm_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov3am_15Hz_8x8/AR4_Nov3am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov4am_15Hz_8x8/AR4_Nov4am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov5am_15Hz_8x8/AR4_Nov5am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov6am_15Hz_8x8/AR4_Nov6am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov7am_15Hz_8x8/AR4_Nov7am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov10am_15Hz_8x8/AR4_Nov10am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov11am_15Hz_8x8/AR4_Nov11am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov12am_15Hz_8x8/AR4_Nov12am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov17am_15Hz_8x8/AR4_Nov17am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov19am_15Hz_8x8/AR4_Nov19am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov21am_15Hz_8x8/AR4_Nov21am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov22am_15Hz_8x8/AR4_Nov22am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov23am_15Hz_8x8/AR4_Nov23am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov24am_15Hz_8x8/AR4_Nov24am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov25am_15Hz_8x8/AR4_Nov25am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov26am_15Hz_8x8/AR4_Nov26am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov27am_15Hz_8x8/AR4_Nov27am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Nov30am_15Hz_8x8/AR4_Nov30am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec1am_15Hz_8x8/AR4_Dec1am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec2am_15Hz_8x8/AR4_Dec2am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec3am_15Hz_8x8/AR4_Dec3am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec8am_15Hz_8x8/AR4_Dec8am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec9am_15Hz_8x8/AR4_Dec9am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec10am_15Hz_8x8/AR4_Dec10am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec11am_15Hz_8x8/AR4_Dec11am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec12am_15Hz_8x8/AR4_Dec12am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec15am_15Hz_8x8/AR4_Dec15am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec16am_15Hz_8x8/AR4_Dec16am_15Hz_8x8.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/AR4/tif_files/AR4_Dec17am_15Hz_8x8/AR4_Dec17am_15Hz_8x8.tif']\n"
     ]
    }
   ],
   "source": [
    "data= np.load('/media/cat/4TBSSD/yuki/AR4/tif_files.npy')\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb1_30Hz/IA1pm_Feb1_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb2_30Hz/IA1pm_Feb2_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb3_30Hz/IA1pm_Feb3_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb4_30Hz/IA1pm_Feb4_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb5_30Hz/IA1pm_Feb5_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb9_30Hz/IA1pm_Feb9_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb10_30Hz/IA1pm_Feb10_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb11_30Hz/IA1pm_Feb11_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb12_30Hz/IA1pm_Feb12_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb15_30Hz/IA1pm_Feb15_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb16_30Hz/IA1pm_Feb16_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb17_30Hz/IA1pm_Feb17_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb18_30Hz/IA1pm_Feb18_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb19_30Hz/IA1pm_Feb19_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb22_30Hz/IA1pm_Feb22_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb23_30Hz/IA1pm_Feb23_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb24_30Hz/IA1pm_Feb24_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb25_30Hz/IA1pm_Feb25_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb26_30Hz/IA1pm_Feb26_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Feb29_30Hz/IA1pm_Feb29_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar1_30Hz/IA1pm_Mar1_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar2_30Hz/IA1pm_Mar2_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar3_30Hz/IA1pm_Mar3_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_Mar4_30Hz/IA1am_Mar4_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_Mar7_30Hz/IA1am_Mar7_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar8_30Hz/IA1pm_Mar8_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_Mar9_30Hz/IA1am_Mar9_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_Mar10_30Hz/IA1am_Mar10_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_Mar11_30Hz/IA1am_Mar11_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar14_30Hz/IA1pm_Mar14_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_Mar15_30Hz/IA1am_Mar15_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar16_30Hz/IA1pm_Mar16_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar17_30Hz/IA1pm_Mar17_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar18_30Hz/IA1pm_Mar18_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar21_30Hz/IA1pm_Mar21_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar22_30Hz/IA1pm_Mar22_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar23_30Hz/IA1pm_Mar23_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar24_30Hz/IA1pm_Mar24_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar29_30Hz/IA1pm_Mar29_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar30_30Hz/IA1pm_Mar30_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Mar31_30Hz/IA1pm_Mar31_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr1_30Hz/IA1pm_Apr1_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr4_30Hz/IA1pm_Apr4_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr5_30Hz/IA1pm_Apr5_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr6_30Hz/IA1pm_Apr6_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr7_30Hz/IA1pm_Apr7_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr11_Day3_30Hz/IA1pm_Apr11_Day3_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr13_Day5_30Hz/IA1pm_Apr13_Day5_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr15_Day7_30Hz/IA1pm_Apr15_Day7_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr18_Week2_30Hz/IA1pm_Apr18_Week2_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr19_Week2_30Hz/IA1pm_Apr19_Week2_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr20_Week2_30Hz/IA1pm_Apr20_Week2_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr21_Week2_30Hz/IA1pm_Apr21_Week2_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr22_Week2_30Hz/IA1pm_Apr22_Week2_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr25_Week3_30Hz/IA1pm_Apr25_Week3_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr26_Week3_30Hz/IA1pm_Apr26_Week3_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr27_Week3_30Hz/IA1pm_Apr27_Week3_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr28_Week3_30Hz/IA1pm_Apr28_Week3_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1pm_Apr29_Week3_30Hz/IA1pm_Apr29_Week3_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May2_Week4_30Hz/IA1am_May2_Week4_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May4_Week4_30Hz/IA1am_May4_Week4_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May5_Week4_30Hz/IA1am_May5_Week4_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May6_Week4_30Hz/IA1am_May6_Week4_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May9_Week5_30Hz/IA1am_May9_Week5_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May10_Week5_30Hz/IA1am_May10_Week5_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May12_Week5_30Hz/IA1am_May12_Week5_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May13_Week5_30Hz/IA1am_May13_Week5_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May16_Week6_30Hz/IA1am_May16_Week6_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May17_Week6_30Hz/IA1am_May17_Week6_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May18_Week6_30Hz/IA1am_May18_Week6_30Hz.tif'\n",
      " '/media/cat/12TB/in_vivo/tim/yuki/IA1/tif_files/IA1am_May20_Week6_30Hz/IA1am_May20_Week6_30Hz.tif']\n"
     ]
    }
   ],
   "source": [
    "print (np.load('/media/cat/4TBSSD/yuki/IA1/tif_files.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['df_with_missing']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = \"/home/cat/Downloads/AR4_2014-12-02_12-56-34.975DLC_resnet50_yuki_leverJul21shuffle1_200000.h5\"\n",
    "\n",
    "f = h5py.File(filename, \"r\")\n",
    "# List all groups\n",
    "print(\"Keys: %s\" % f.keys())\n",
    "a_group_key = list(f.keys())[0]\n",
    "\n",
    "# Get the data\n",
    "data = list(f[a_group_key])\n",
    "\n",
    "data2 = f['df_with_missing']['table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "print (data2[0][1].shape)\n",
    "\n",
    "traces = []\n",
    "for k in range(len(data2)):\n",
    "    traces.append(data2[k][1].reshape(-1,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20066, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "traces = np.array(traces)\n",
    "print (traces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2be8bd57af7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/cat/4TBSSD/yuki/IJ1/tif_files.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "files = np.load('/media/cat/4TBSSD/yuki/IJ1/tif_files.npy')\n",
    "print (files[0].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 35, 901)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/4TBSSD/yuki/IA1/tif_files/IA1am_Mar15_30Hz/IA1am_Mar15_30Hz_code_04_lockout_15sec_trial_ROItimeCourses_15sec.npy')\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 35, 901)\n",
      "(18, 35, 901)\n",
      "(14, 35, 901)\n",
      "(50, 35, 901)\n",
      "\n",
      "(18, 35, 901)\n",
      "(19, 35, 901)\n",
      "(15, 35, 901)\n",
      "(50, 35, 901)\n"
     ]
    }
   ],
   "source": [
    "fnames = [\n",
    "'/home/cat/Downloads/drive-download-20210216T163926Z-001/IA1am_Mar11_30Hz_code_04_lockout_15sec_random_trial_timeCourses_15sec.npy',\n",
    "'/home/cat/Downloads/drive-download-20210216T163926Z-001/IA1pm_Mar14_30Hz_code_04_lockout_15sec_random_trial_timeCourses_15sec.npy',\n",
    "'/home/cat/Downloads/drive-download-20210216T163926Z-001/IA1am_Mar15_30Hz_code_04_lockout_15sec_random_trial_timeCourses_15sec.npy',\n",
    "]\n",
    "\n",
    "temp = []\n",
    "for fname in fnames:\n",
    "    data = np.load(fname)\n",
    "    print (data.shape)\n",
    "    temp.extend(data)\n",
    "    \n",
    "temp = np.array(temp)\n",
    "print (temp.shape)\n",
    "\n",
    "np.save('/home/cat/random.npy', temp)\n",
    "print ('')   \n",
    "    \n",
    "fnames = [\n",
    "    \n",
    "'/home/cat/Downloads/drive-download-20210216T163926Z-001/IA1am_Mar11_30Hz_code_04_lockout_15sec_trial_ROItimeCourses_15sec.npy',\n",
    "'/home/cat/Downloads/drive-download-20210216T163926Z-001/IA1pm_Mar14_30Hz_code_04_lockout_15sec_trial_ROItimeCourses_15sec.npy',\n",
    "'/home/cat/Downloads/drive-download-20210216T163926Z-001/IA1am_Mar15_30Hz_code_04_lockout_15sec_trial_ROItimeCourses_15sec.npy',\n",
    "]\n",
    "\n",
    "temp = []\n",
    "for fname in fnames:\n",
    "    data = np.load(fname)\n",
    "    print (data.shape)\n",
    "    temp.extend(data)\n",
    "    \n",
    "temp = np.array(temp)[:50]\n",
    "print (temp.shape)\n",
    "\n",
    "np.save('/home/cat/trials.npy', temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
