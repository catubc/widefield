{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f254106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-9bc938cb63d7>:11: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib tk\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%autosave 180\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# visualize results module\n",
    "from visualize import visualize_svm as Visualize\n",
    "\n",
    "import scipy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6761d0-6932-4ee9-9f03-52206375190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#############################################\n",
    "#############################################\n",
    "\n",
    "class PCA_Analysis():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.clr_ctr = 0\n",
    "        \n",
    "        \n",
    "def get_pca_object_and_all_points(pa):\n",
    "\n",
    "    fname_pickle = os.path.join(pa.root_dir, pa.animal_id,'tif_files',pa.session,\n",
    "                                pa.session+\"_pca_scatter_plot.pk\")\n",
    "\n",
    "    fname_all_points = os.path.join(pa.root_dir, pa.animal_id,'tif_files',pa.session,\n",
    "                                pa.session+\"_all_points.npy\")\n",
    "    X_30 = []\n",
    "    for k in range(0,pa.X.shape[0]-100,pa.sliding_window):\n",
    "        X_30.append(pa.X[k:k+pa.sliding_window])\n",
    "\n",
    "    #\n",
    "    X_30 = np.array(X_30)\n",
    "    X_30 = X_30.reshape(X_30.shape[0],-1)\n",
    "    print(\" X data using : \", pa.sliding_window, \" number of frames \", X_30.shape)\n",
    "\n",
    "    if os.path.exists(fname_all_points)==False:\n",
    "\n",
    "        # PCA ON ALL DATA\n",
    "        pca = PCA(n_components=pa.n_pca)\n",
    "        pca.fit(X_30)\n",
    "        print (\" done fit \")\n",
    "\n",
    "        # do\n",
    "        all_points = pca.transform(X_30)\n",
    "        print (\"all points denoised: \", all_points.shape)\n",
    "\n",
    "        with open(fname_pickle, 'wb') as f:\n",
    "            pickle.dump(pca, f)\n",
    "\n",
    "        np.save(fname_all_points,\n",
    "                all_points)\n",
    "    else:\n",
    "\n",
    "        with open(fname_pickle, \"rb\") as f:\n",
    "            pca = pickle.load(f)\n",
    "        all_points = np.load(fname_all_points)\n",
    "\n",
    "    return pca, all_points\n",
    "\n",
    "\n",
    "\n",
    "def get_convex_hull(pa):\n",
    "\n",
    "    ''' COMPUTE CONVEX HULL\n",
    "        - \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # do very basic KNN triage\n",
    "    n_dim = 3\n",
    "\n",
    "    if True:\n",
    "\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        triage_value = 0.001\n",
    "        knn_triage_threshold = 100*(1-triage_value)\n",
    "\n",
    "        #if pca_wf.shape[0] > 1/triage_value:\n",
    "        temp_points = pa.all_points[:,:n_dim]\n",
    "        print (\"temp points: \", temp_points.shape)\n",
    "        idx_keep = knn_triage(knn_triage_threshold, temp_points)\n",
    "        idx_keep = np.where(idx_keep==1)[0]\n",
    "\n",
    "        print (\"# points kept: \", idx_keep.shape,\n",
    "               \" of total: \", pa.all_points.shape[0])\n",
    "\n",
    "        temp_points = temp_points[idx_keep]\n",
    "\n",
    "    ######################################\n",
    "    print (\"computing convex hull # dim: \", n_dim, temp_points.shape)\n",
    "    hull_all = ConvexHull(temp_points)\n",
    "\n",
    "    #\n",
    "    ratio_cumsum = []\n",
    "    ratio_single = []\n",
    "    ratio_random_single = []\n",
    "    ratio_random_cumulative = []\n",
    "    print (\"p lever: \", pa.p_lever.shape)\n",
    "    for k in trange(0, pa.p_lever.shape[0],1):\n",
    "\n",
    "        # single frame convex hull; (frame???, n_times_points, n_dimensions)\n",
    "        points = pa.p_lever[k:k+1,:,:n_dim].squeeze()#.reshape(-1,3)\n",
    "        try:\n",
    "            hull11 = ConvexHull(points)\n",
    "        except:\n",
    "            continue\n",
    "        ratio_single.append(hull11.volume/hull_all.volume)\n",
    "\n",
    "        # cumulative convex hull\n",
    "        points = pa.p_lever[:k+1,:,:n_dim].reshape(-1,n_dim)\n",
    "        #if k<10:\n",
    "        #    print (\"cumulative: \", points.shape)\n",
    "        hull1 = ConvexHull(points)\n",
    "        ratio_cumsum.append(hull1.volume/hull_all.volume)\n",
    "\n",
    "        #\n",
    "        #idx = np.random.randint(0,temp_points.shape[0],p_lever.shape[1])\n",
    "        id_ = np.random.randint(0,temp_points.shape[0]-500,1)\n",
    "        idx = np.arange(id_,id_+pa.p_lever.shape[1])\n",
    "        points_random = temp_points[idx,:n_dim]\n",
    "        hull3 = ConvexHull(points_random)\n",
    "        ratio_random_single.append(hull3.volume/hull_all.volume)\n",
    "\n",
    "        #\n",
    "        ratio_random_cumulative.append([])\n",
    "        for q in range(10):\n",
    "            if True:\n",
    "                idx = np.random.randint(0,temp_points.shape[0],\n",
    "                                        pa.p_lever.shape[1]*(k+1))\n",
    "            else:\n",
    "                ns = np.random.randint(0,temp_points.shape[0]-500,k+1)\n",
    "                idx = []\n",
    "                for s in range(ns.shape[0]):\n",
    "                    idx.append(np.arange(ns[s],ns[s]+pa.p_lever.shape[1]))\n",
    "                idx=np.hstack(idx)\n",
    "            points_random = temp_points[idx]\n",
    "            #if q==0 and k<10:\n",
    "            #    print (points_random.shape)\n",
    "            hull4 = ConvexHull(points_random)\n",
    "            ratio_random_cumulative[k].append(hull4.volume/hull_all.volume)\n",
    "\n",
    "    pa.ratio_single = np.array(ratio_single)[::-1]\n",
    "    pa.ratio_cumsum = np.array(ratio_cumsum)[::-1]\n",
    "    pa.ratio_random_single = np.array(ratio_random_single)[::-1]\n",
    "    pa.ratio_random_cumulative = np.array(ratio_random_cumulative)[::-1]\n",
    "\n",
    "    print (pa.ratio_random_cumulative.shape)\n",
    "    print (pa.ratio_random_single.shape)\n",
    "\n",
    "    fname_out = os.path.join(pa.root_dir,\n",
    "                             pa.animal_id,\n",
    "                             'tif_files',\n",
    "                             pa.session,\n",
    "                             pa.session+\"_convex_hull.npz\")\n",
    "\n",
    "    np.savez(fname_out,\n",
    "             ratio_single = ratio_single,\n",
    "             ratio_cumsum = ratio_cumsum,\n",
    "             ratio_random_single = ratio_random_single,\n",
    "             ratio_random_cumulative = ratio_random_cumulative\n",
    "             )\n",
    "\n",
    "    return pa\n",
    "\n",
    "\n",
    "        \n",
    "def knn_triage(th, pca_wf):\n",
    "\n",
    "    tree = cKDTree(pca_wf)\n",
    "    dist, ind = tree.query(pca_wf, k=6)\n",
    "    dist = np.sum(dist, 1)\n",
    "\n",
    "    idx_keep1 = dist <= np.percentile(dist, th)\n",
    "    return idx_keep1\n",
    "\n",
    "\n",
    "def triage_distributions(X_pca):\n",
    "\n",
    "    # use knn triage to remove most outlier points\n",
    "    triage_value = 0.01\n",
    "    thresh = 100*(1-triage_value)\n",
    "\n",
    "    # apply knn to all points\n",
    "    #temp_points = X[:,:2]\n",
    "\n",
    "    idx_keep = knn_triage(thresh, X_pca)\n",
    "    idx_keep = np.where(idx_keep==1)[0]\n",
    "    #all_points_knn = temp_points[idx_keep]\n",
    "    \n",
    "    X = X_pca[idx_keep]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d88ef94-2075-4d40-abd1-fe82d2065d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310, 300, 16)\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "#################################################################\n",
    "#################################################################\n",
    "animal_ids = ['IA1','IA2','IA3','IJ1','IJ2','AQ2']\n",
    "\n",
    "times = [600,900]\n",
    "\n",
    "\n",
    "# \n",
    "fname = '/media/cat/4TBSSD/yuki/IA3/super_sessions/alldata_body_and_nonreward_lockout_12secLockout_[]bodyfeats.npz'\n",
    "data = np.load(fname,allow_pickle=True)\n",
    "trials = data['trials']\n",
    "trials = np.vstack(trials)[:,times[0]:times[1]]\n",
    "print (trials.shape)\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4294bd3f-d9ca-4619-8aa7-70adf9926207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39000, 16)\n",
      " X data using :  30  number of frames  (1297, 480)\n",
      "computing convex hull # dim:  3 (1284, 3)\n",
      "all points hull volume:  28638367411.027306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2/21 [00:00<00:01, 17.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sessions:  (503, 1800, 16)  example session:  (1800, 16)\n",
      "trials: -10sec to 0sec (# of trials, # of frames, # of ROIs):  (503, 300, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation:  (0.8009287445429161, 0.00011181261176070025)\n",
      "(39000, 16)\n",
      " X data using :  30  number of frames  (1297, 480)\n",
      "computing convex hull # dim:  3 (1284, 3)\n",
      "all points hull volume:  16323950213.598078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3/23 [00:00<00:00, 20.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sessions:  (564, 1800, 16)  example session:  (1800, 16)\n",
      "trials: -10sec to 0sec (# of trials, # of frames, # of ROIs):  (564, 300, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 26.73it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation:  (-0.25945549937410883, 0.2834204520392138)\n",
      "(39000, 16)\n",
      " X data using :  30  number of frames  (1297, 480)\n",
      "computing convex hull # dim:  3 (1284, 3)\n",
      "all points hull volume:  18608687099.552956\n",
      "# sessions:  (188, 1800, 16)  example session:  (1800, 16)\n",
      "trials: -10sec to 0sec (# of trials, # of frames, # of ROIs):  (188, 300, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 50.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation:  (-0.15099415300784574, 0.8490058469921542)\n",
      "(39000, 16)\n",
      " X data using :  30  number of frames  (1297, 480)\n",
      "computing convex hull # dim:  3 (1284, 3)\n",
      "all points hull volume:  13792327943.12256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [00:00<00:00, 33.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sessions:  (261, 1800, 16)  example session:  (1800, 16)\n",
      "trials: -10sec to 0sec (# of trials, # of frames, # of ROIs):  (261, 300, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 34.61it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation:  (0.10531512983885039, 0.8222013274243782)\n",
      "(39000, 16)\n",
      " X data using :  30  number of frames  (1297, 480)\n",
      "computing convex hull # dim:  3 (1284, 3)\n",
      "all points hull volume:  10720526840.661592\n",
      "# sessions:  (139, 1800, 16)  example session:  (1800, 16)\n",
      "trials: -10sec to 0sec (# of trials, # of frames, # of ROIs):  (139, 300, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 69.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation:  (-1.0, 1.0)\n",
      "(39000, 16)\n",
      " X data using :  30  number of frames  (1297, 480)\n",
      "computing convex hull # dim:  3 (1284, 3)\n",
      "all points hull volume:  4215382219.1976748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:00<00:01, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sessions:  (594, 1800, 16)  example session:  (1800, 16)\n",
      "trials: -10sec to 0sec (# of trials, # of frames, # of ROIs):  (594, 300, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation:  (0.6834805976249893, 0.000892984335025864)\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "#############################################\n",
    "#############################################\n",
    "\n",
    "# steps:\n",
    "# 1. get multiple sessoin locaNMF traces \n",
    "# 2. chunk them into 30 frame bits\n",
    "# 3. \n",
    "\n",
    "# \n",
    "import pickle\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial import ConvexHull\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "root_dir = '/media/cat/4TBSSD/yuki/'\n",
    "\n",
    "#\n",
    "pa = PCA_Analysis()\n",
    "pa.root_dir = root_dir #\n",
    "\n",
    "#\n",
    "pa.use_pca_data = True    # this uses the PCA denoised STMs not Raw data!\n",
    "pa.recompute = True\n",
    "pa.n_pca = 20\n",
    "pa.sliding_window = 30    # how many frames to take into analysis window\n",
    "pa.n_frames = 300          # how many frames back in time to analyze:\n",
    "\n",
    "\n",
    "animal_ids = ['IA1','IA2','IA3','IJ1','IJ2','AQ2']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "ctr2=0\n",
    "for animal_id in animal_ids:\n",
    "\n",
    "    ax = plt.subplot(3,2,ctr2+1)\n",
    "    pa.animal_id = animal_id\n",
    "\n",
    "    if animal_id != 'AQ2':\n",
    "        pa.session = animal_id+'pm_Mar30_30Hz'\n",
    "    else:\n",
    "        pa.session = animal_id + 'am_Mar30_Week4_30Hz'\n",
    "\n",
    "    ###########################################################\n",
    "    ##### Load wholestack of locanmf data and run PCA #########\n",
    "    ###########################################################\n",
    "    # load wholstacks of data; \n",
    "    # may wish to load multiple sessions\n",
    "    fname_data = os.path.join(pa.root_dir,\n",
    "                              pa.animal_id,\n",
    "                              'tif_files',\n",
    "                              pa.session,\n",
    "                              pa.session+'_locanmf_wholestack.npz')\n",
    "\n",
    "    pa.X = np.load(fname_data,allow_pickle=True)['whole_stack'].T[500:-500]  # remove the beginning and end due to imaging issues\n",
    "    print (pa.X.shape)\n",
    "\n",
    "    # run PCA\n",
    "    X_30 = []\n",
    "    for k in range(0,pa.X.shape[0]-100,pa.sliding_window):\n",
    "        X_30.append(pa.X[k:k+pa.sliding_window])\n",
    "\n",
    "    #\n",
    "    X_30 = np.array(X_30)\n",
    "    X_30 = X_30.reshape(X_30.shape[0],-1)\n",
    "    print(\" X data using : \", pa.sliding_window, \" number of frames \", X_30.shape)\n",
    "\n",
    "    fname_pickle = fname_data[:-4]+\"_pca_scatter_plot.pk\"\n",
    "    fname_all_points = fname_data[:-4]+\"_all_points.npy\"\n",
    "\n",
    "    if os.path.exists(fname_all_points)==False:\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        # PCA ON ALL DATA\n",
    "        pca = PCA(n_components=pa.n_pca)\n",
    "        pca.fit(X_30)\n",
    "        print (\" done fit \")\n",
    "\n",
    "        # do\n",
    "        all_points = pca.transform(X_30)\n",
    "        print (\"all points denoised: \", all_points.shape)\n",
    "\n",
    "        with open(fname_pickle, 'wb') as f:\n",
    "            pickle.dump(pca, f)\n",
    "\n",
    "        np.save(fname_all_points,\n",
    "                all_points)\n",
    "    else:\n",
    "\n",
    "        with open(fname_pickle, \"rb\") as f:\n",
    "            pca = pickle.load(f)\n",
    "        all_points = np.load(fname_all_points)\n",
    "\n",
    "    ####################################################\n",
    "    ########## Load locked out super sessions ##########\n",
    "    ####################################################\n",
    "    all_points = triage_distributions(all_points)\n",
    "    n_dim = 3\n",
    "    print (\"computing convex hull # dim: \", n_dim, all_points[:,:n_dim].shape)\n",
    "    hull_all = ConvexHull(all_points[:,:n_dim])\n",
    "    print (\"all points hull volume: \",hull_all.volume)\n",
    "\n",
    "    # load the lockout data\n",
    "    fname_data = os.path.join(pa.root_dir,\n",
    "                              pa.animal_id,\n",
    "                              'super_sessions',\n",
    "                              'alldata_body_and_nonreward_lockout_15secLockout_[]bodyfeats.npz')\n",
    "\n",
    "    data = np.load(fname_data,allow_pickle=True)\n",
    "    trials = np.vstack(data['trials'])\n",
    "    print (\"# sessions: \", trials.shape,\" example session: \", trials[0].shape)\n",
    "    start = 600\n",
    "    end = 900\n",
    "    trials = trials[:,start:end]\n",
    "    print (\"trials: -10sec to 0sec (# of trials, # of frames, # of ROIs): \", trials.shape)\n",
    "\n",
    "    ####################################################\n",
    "    ### apply previous computed PCA on superssession ###\n",
    "    ####################################################\n",
    "    aucs_norm = []\n",
    "    session_n = []\n",
    "    ctr = 0\n",
    "    n_trials = 100\n",
    "    for e in trange(0,trials.shape[0],25):\n",
    "        ratio_cumsum = []\n",
    "        for k in range(0,300,10):\n",
    "            temp = trials[e:e+n_trials,k:k+pa.sliding_window]\n",
    "            if temp.shape[0]!=n_trials or temp.shape[1]!=pa.sliding_window:\n",
    "                break\n",
    "\n",
    "            #print (\"temp: \", temp.shape)\n",
    "            temp = temp.reshape(n_trials,-1)\n",
    "            # print (\"temp reshaped: \", temp.shape)\n",
    "\n",
    "            pca_lever = pca.transform(temp)\n",
    "            #print (\"pca_lever: \", pca_lever.shape)\n",
    "\n",
    "            # cumulative convex hull\n",
    "            points = pca_lever[:,:n_dim].reshape(-1,n_dim)\n",
    "            hull1 = ConvexHull(points)\n",
    "            ratio_cumsum.append(hull1.volume/hull_all.volume)\n",
    "            #print (\"hull1 volume: \", hull1.volume)\n",
    "\n",
    "        try:\n",
    "            #print (\"ratio: \", ratio_cumsum)\n",
    "            #print (\"max: \", np.max(ratio_cumsum))\n",
    "            aucs_norm.append((ratio_cumsum/np.max(ratio_cumsum)).sum())\n",
    "            session_n.append(ctr)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ctr+=1\n",
    "        #plt.scatter(np.arange(len(ratio_cumsum)), ratio_cumsum)\n",
    "\n",
    "    ######################################################\n",
    "    ######################################################\n",
    "    ######################################################\n",
    "\n",
    "    plt.scatter(session_n, \n",
    "                aucs_norm, \n",
    "                s=300,\n",
    "                edgecolor='black',\n",
    "                #label=animal_id,\n",
    "                c='red',\n",
    "                alpha=.65)\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from scipy import stats\n",
    "\n",
    "    model = LinearRegression()\n",
    "    y=np.array(aucs_norm).reshape(-1, 1)\n",
    "    x = np.array(session_n).reshape(-1, 1)\n",
    "    model.fit(x, y)\n",
    "\n",
    "    x2 = np.arange(0,y.shape[0],1).reshape(-1, 1)\n",
    "    y_pred = model.intercept_ + model.coef_ * x2\n",
    "\n",
    "    # compute correlation between time and location\n",
    "    corr = stats.pearsonr(x.squeeze(),y.squeeze())\n",
    "    print (\"pearson correlation: \", corr)\n",
    "\n",
    "    plt.plot(x2, y_pred, \n",
    "             label= \"pcorr: \"+str(round(corr[0],5))+\"\\npval: \"+\n",
    "                             str(round(corr[1],5)),\n",
    "             c='black',\n",
    "             linewidth=10)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    #plt.ylim(bottom=0)\n",
    "    plt.xlim(x[0],x[-1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    #\n",
    "    ctr2+=1\n",
    "    \n",
    "# \n",
    "if True:\n",
    "    plt.savefig('/home/cat/AUCs_all_animals.svg')\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cefe8805-cb67-40d8-b2ab-864e92e0c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = triage_distributions(all_points)\n",
    "plt.figure()\n",
    "plt.scatter(x2[:,0],\n",
    "            x2[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ab978-8885-475b-9099-46af9206687f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf93e3c-1852-4354-8a66-e1ef06905031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a296305-1cd2-4ead-977d-d87ad61a6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 16)\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "###############################################\n",
    "###############################################\n",
    "locanmf = np.load('/media/cat/4TBSSD/yuki/IA1/tif_files/IA1pm_Mar30_30Hz/IA1pm_Mar30_30Hz_locanmf_wholestack.npz',\n",
    "                  allow_pickle=True)\n",
    "\n",
    "whole_stack = locanmf['whole_stack'].T\n",
    "print (whole_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400a802-8dc6-4b1f-83d4-c3ad1eba48ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18611e37-5804-4ffe-968c-c982806b4768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f1d3c-9725-4c14-b1a6-e8e9722ba844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d48d03-ff38-47c1-9e74-0aacbad294c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb7047-e37a-4589-8b29-f4a1d1b37949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457b6be-9dd0-4848-99fc-895a291db114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90381cd-38ce-478c-8fdb-951111f33413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3dce5600-a61a-4125-a286-48aadb5b01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "########### HELPER FUNCTIONS ##############\n",
    "###########################################\n",
    "def load_reward_times(root_dir,\n",
    "                      animal_id,\n",
    "                      sessions,\n",
    "                      width):\n",
    "    # load rewarded and nonrewarded times in miliseconds\n",
    "    rtimes = np.loadtxt(os.path.join(root_dir,\n",
    "                                  animal_id,\n",
    "                                  'tif_files',\n",
    "                                  sessions[0],\n",
    "                                  'rewarded_times.txt'))*1E3\n",
    "\n",
    "    #\n",
    "    nonrtimes = np.loadtxt(os.path.join(root_dir,\n",
    "                                  animal_id,\n",
    "                                  'tif_files',\n",
    "                                  sessions[0],\n",
    "                                  'nonrewarded_times.txt'))*1E3\n",
    "\n",
    "    # add all data togheter\n",
    "    # rtimes = np.concatenate((rtimes, nonrtimes))\n",
    "\n",
    "    # \n",
    "    rtimes_random = []\n",
    "    for k in range(rtimes.shape[0]):\n",
    "        temp = rtimes[k] \n",
    "        rr = (np.random.rand(1)*50-25)*1E3\n",
    "        #print (temp, rr)\n",
    "        rtimes_random.append(temp+rr)\n",
    "\n",
    "    # convolve all data with gaussian\n",
    "\n",
    "    start = -10*1E3\n",
    "    end = 10*1E3\n",
    "    x = np.arange(start, end, 1) # entire range of x, both in and out of spec\n",
    "    std = 1.5*1E3  # std in miliseconds\n",
    "    mu = 0\n",
    "    y = scipy.stats.norm.pdf(x,mu,std) \n",
    "\n",
    "    t = np.zeros(int(1400*1E3))\n",
    "    for r in tqdm(rtimes):\n",
    "        try:\n",
    "            t[int(r+start):int(r+end)]+=y\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    t_random = np.zeros(int(1400*1E3))\n",
    "    for r in tqdm(rtimes_random):\n",
    "        try:\n",
    "            t_random[int(r+start):int(r+end)]+=y\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #####################################\n",
    "    # stack segments on top of each other\n",
    "    stack = []\n",
    "    stack_random = []\n",
    "    for r in tqdm(rtimes):\n",
    "        temp = t[int(r-width):int(r+width)]\n",
    "        if temp.shape[0]==(2*width):\n",
    "            stack.append(temp)\n",
    "\n",
    "        temp = t_random[int(r-width):int(r+width)]\n",
    "        if temp.shape[0]==(2*width):\n",
    "            stack_random.append(temp)\n",
    "\n",
    "\n",
    "    stack = np.vstack(stack).T\n",
    "    stack_random = np.vstack(stack_random).T\n",
    "    print (\"stacK: \", stack.shape)\n",
    "\n",
    "    ######################################\n",
    "    # sample back down to 30Hz\n",
    "    t = t[::30]\n",
    "    x = np.arange(t.shape[0])/30.\n",
    "    \n",
    "    return x, t, stack, stack_random\n",
    "\n",
    "#\n",
    "def plot_n_trials_per_session(root_dir,\n",
    "                             animal_id,\n",
    "                             session_id):\n",
    "\n",
    "    arr = []\n",
    "    ctr=0\n",
    "    for animal_id in animal_ids:\n",
    "        sessions = Visualize.get_sessions(root_dir,\n",
    "                                          animal_id,\n",
    "                                          session_id)\n",
    "\n",
    "\n",
    "        # load rewarded and nonrewarded times in miliseconds\n",
    "        rtimes = np.loadtxt(os.path.join(root_dir,\n",
    "                                      animal_id,\n",
    "                                      'tif_files',\n",
    "                                      sessions[0],\n",
    "                                      'rewarded_times.txt'))\n",
    "\n",
    "        # load rewarded and nonrewarded times in miliseconds\n",
    "        n_trials = []\n",
    "        for session in tqdm(sessions):\n",
    "            try:\n",
    "                import warnings\n",
    "                with warnings.catch_warnings():\n",
    "                     warnings.simplefilter(\"ignore\")\n",
    "                     #data = np.loadtxt(myfile, unpack=True)\n",
    "                     rtimes = np.loadtxt(os.path.join(root_dir,\n",
    "                                          animal_id,\n",
    "                                          'tif_files',\n",
    "                                          session,\n",
    "                                          'rewarded_times.txt'), unpack=True)\n",
    "                if rtimes.shape[0]>30:\n",
    "                    n_trials.append(rtimes.shape[0])\n",
    "            except:\n",
    "                pass\n",
    "        n_trials = np.array(n_trials)\n",
    "        idx = np.where(np.isnan(n_trials)==False)[0]\n",
    "        n_trials = n_trials[idx]\n",
    "\n",
    "        arr.append(n_trials)\n",
    "        ctr+=1\n",
    "        #if ctr>1:\n",
    "        #    break\n",
    "\n",
    "    #####################################\n",
    "    linestyles = ['-','-','-']\n",
    "    pvals = [0.05,0.01,0.001,0.0001,0.00001]\n",
    "    my_dict = dict(\n",
    "                    M1 = arr[0], \n",
    "                    M2 = arr[1], \n",
    "                    M3 = arr[2], \n",
    "                    M4 = arr[3], \n",
    "                    M5 = arr[4], \n",
    "                    M6 = arr[5],                \n",
    "                  )\n",
    "\n",
    "    # \n",
    "    #cons.append(edts[1])\n",
    "    data = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    data = data.transpose()\n",
    "\n",
    "    ###############################################\n",
    "    ########## PLOT SCATTER #######################\n",
    "    ###############################################\n",
    "    fig = plt.figure(figsize=(24,8))\n",
    "    clrs_local = [\"black\",\"black\",\"black\",\"black\",\"black\",\"black\",] #,\"red\"]\n",
    "    for i,d in enumerate(data):\n",
    "        y = data[d]\n",
    "        #print ('y: ', y)\n",
    "        x = np.random.normal(i+1, 0.04, len(y))\n",
    "        if True:\n",
    "            plt.plot(x, y, \n",
    "                 mfc =clrs_local[i], \n",
    "                 mec='k', \n",
    "                 ms=7, \n",
    "                 marker=\"o\", \n",
    "                 linestyle=\"None\",\n",
    "                 alpha=.8\n",
    "                )\n",
    "        else:\n",
    "            plt.scatter(x, y, \n",
    "                   c=clrs_local[i],\n",
    "                   edgecolor='black',\n",
    "                   s=200,\n",
    "                   alpha=.7)\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "    ########## PLOT  #######################\n",
    "    ###############################################\n",
    "    flierprops = dict(marker='o', \n",
    "                      #markerfacecolor='g', \n",
    "                      markersize=10000,\n",
    "                      linestyle='none', \n",
    "                      markeredgecolor='r')\n",
    "\n",
    "    #\n",
    "    bplot = data.boxplot(showfliers=True,\n",
    "                flierprops=flierprops,\n",
    "                grid=False) \n",
    "\n",
    "    plt.ylabel(\"# of trials in session\")\n",
    "\n",
    "    #\n",
    "    plt.ylim(29,200)  \n",
    "    \n",
    "#   \n",
    "def plot_average_convolution(width, stack, stack_random):\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    t= np.arange(-width,width,1)/1E3\n",
    "    plt.plot(t,stack,c='blue',alpha=.01)\n",
    "    # plt.plot(t,stack[:,0],c='black',alpha=0, label='singletrial')\n",
    "    signal = stack.mean(1)\n",
    "    plt.plot(t,signal,\n",
    "             c='darkblue',\n",
    "             linewidth=3,\n",
    "             label=\"Session average\")\n",
    "    #\n",
    "    if True:\n",
    "        signal_random = stack_random.mean(1)\n",
    "        plt.plot(t,signal_random,\n",
    "                 c='darkred',\n",
    "                 linewidth=3,\n",
    "                 alpha=.7,\n",
    "                 label=\"Session average - random\")\n",
    "\n",
    "\n",
    "        \n",
    "    plt.plot([-3,-3],\n",
    "             [0,0.00030],'--',\n",
    "            c='black')\n",
    "    plt.plot([3,3],\n",
    "             [0,0.00030],'--',\n",
    "            c='black')\n",
    "    plt.xlim(t[0],t[-1])\n",
    "    xticks=[-50,-40,-30,-20,-10,-3,0,\n",
    "            3,10,20,30,40,50]\n",
    "    plt.xticks(xticks)\n",
    "    plt.xlabel(\"Time (sec)\")\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.title(sessions[0]+ \" # of trials: \"+ str(stack.shape[1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#    \n",
    "# def plot_average_convolution_hilbert(width, stack, stack_random):\n",
    "\n",
    "#     # this function works on the simulated neural signals; so thereare no ROIs\n",
    "    \n",
    "#     plt.figure(figsize=(8,8))\n",
    "#     print (\"stack: \", stack.shape)\n",
    "#     mean = stack.mean(1)\n",
    "#     print (\"means: \", mean.shape)\n",
    "    \n",
    "#     #\n",
    "#     analytic_signal = hilbert(mean)\n",
    "#     amplitude_envelope = np.abs(analytic_signal)\n",
    "#     #amplitude_envelope = butter_lowpass_filter(amplitude_envelope,.5,30)\n",
    "\n",
    "#     start = int(0*1E3)\n",
    "#     end = int(1050*1E3)\n",
    "    \n",
    "#     # \n",
    "#     t = mean[start:end]\n",
    "#     x = np.arange(t.shape[0])/1E3\n",
    "#     amplitude_envelope = amplitude_envelope[start:end]\n",
    "\n",
    "#     #\n",
    "#     plt.plot(x, t, c='darkblue', linewidth=5, label='Average session neural signal')\n",
    "#     plt.plot(x, amplitude_envelope, '--', c='black', linewidth=1, label=\"Hilbert transform envelope\")\n",
    "\n",
    "\n",
    "#     #\n",
    "#     # plt.plot([x[0], x[-1]],[0,0],'--',c='black', linewidth=3)\n",
    "#     # plt.plot([x[600], x[600]],[-5,7],'--',c='black', linewidth=3)\n",
    "\n",
    "    \n",
    "#     #plt.plot(tt,means[:,feature_id],c='blue')\n",
    "#     #plt.plot(t,random.mean(0)[:,4],c='red')\n",
    "#     #plt.xlim(-30,3)\n",
    "#     plt.title(animal_id+\" \" +str(lockout)+\"sec\")\n",
    "#     #ctr+=1\n",
    "    \n",
    "#     #xticks=[-50,-40,-30,-20,-10,-3,0,\n",
    "#     #        3,10,20,30,40,50]\n",
    "#     #plt.xticks(xticks)\n",
    "#     #plt.xlim(t[0],t[-1])\n",
    "    \n",
    "    \n",
    "# #     plt.plot([-3,-3],\n",
    "# #              [0,0.00030],'--',\n",
    "# #             c='black')\n",
    "# #     plt.plot([3,3],\n",
    "# #              [0,0.00030],'--',\n",
    "# #             c='black')\n",
    "   \n",
    "#     plt.xlabel(\"Time (sec)\")\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.title(sessions[0]+ \" # of trials: \"+ str(stack.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b4175e76-8972-4778-9d38-71beebb9fff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 7453.70it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 7283.36it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 90968.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sessions:  ['IA3pm_Feb4_30Hz']\n",
      "stacK:  (100000, 54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "############ LOAD LEVER PULL TIMES ########\n",
    "###########################################\n",
    "root_dir = '/media/cat/4TBSSD/yuki/'\n",
    "animal_id = 'IA1'\n",
    "session_id = 'IA1pm_Feb2_30Hz'\n",
    "session_id = 'IA1pm_Feb16_30Hz'\n",
    "session_id = 'IA1pm_Feb3_30Hz'\n",
    "session_id = 'IA1pm_Feb9_30Hz'\n",
    "\n",
    "animal_id = 'IA2'\n",
    "# session_id = 'IA2pm_Mar14_30Hz'\n",
    "# session_id = 'IA2pm_Feb29_30Hz'\n",
    "session_id = 'IA2pm_Feb3_30Hz'\n",
    "\n",
    "animal_id = 'IA3'\n",
    "# session_id = 'IA3pm_Apr1_30Hz'\n",
    "session_id = 'IA3pm_Feb4_30Hz'\n",
    "\n",
    "\n",
    "#animal_id = 'IJ1'\n",
    "# # session_id = 'IJ1am_Mar10_30Hz'\n",
    "# #session_id = 'IJ1pm_Mar2_30Hz'\n",
    "# session_id = 'IJ1pm_Mar3_30Hz'\n",
    "#session_id = 'IJ1pm_Feb11_30Hz'\n",
    "\n",
    "# animal_id = 'IJ2'\n",
    "# session_id = 'IJ2pm_Apr5_30Hz'\n",
    "# session_id = 'IJ2pm_Feb9_30Hz'\n",
    "\n",
    "#animal_id = 'AQ2'\n",
    "# session_id = 'AQ2am_Apr1_Week4_30Hz'\n",
    "#session_id = 'AQ2am_Dec30_30Hz'\n",
    "# session_id = 'AQ2am_Apr7_Week5_30Hz'\n",
    "# session_id = 'AQ2am_Apr1_Week4_30Hz'\n",
    "\n",
    "# session_id = 'all'\n",
    "# session = session_id  # or 'all'\n",
    "sessions = Visualize.get_sessions(root_dir,\n",
    "                                  animal_id,\n",
    "                                  session_id)\n",
    "\n",
    "# sessions = [sessions[2]]\n",
    "print (\"# sessions: \", sessions)\n",
    "\n",
    "\n",
    "#\n",
    "width= 50*1E3  # in milliseconds\n",
    "\n",
    "x, t, stack, stack_random = load_reward_times(root_dir,\n",
    "                                               animal_id,\n",
    "                                               sessions,\n",
    "                                               width)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0b08d369-18ce-4e6c-aed7-4124208eb595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "####### PLOT CONVOLUTION (LEVER PULL, GAUSSIAN) ACROSS SESSION ######\n",
    "#####################################################################\n",
    "plt.figure(figsize=(24,8))\n",
    "plt.plot(x,t)\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.ylabel(\"Convolution (lever pull time, gaussian)\")\n",
    "plt.yticks([])\n",
    "plt.xlim(x[0],x[-1])\n",
    "if False:\n",
    "    plt.savefig('/home/cat/rtimesgaussian.svg')\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "2549ae74-149a-4ab6-9c3e-a04064f56e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "####### PLOT AVERAGE CONVOLUTION ######\n",
    "####################################### \n",
    "#     \n",
    "plot_average_convolution(width,\n",
    "                         stack,\n",
    "                         stack_random)\n",
    "plt.xlim(-20,5)\n",
    "if True:\n",
    "    plt.savefig('/home/cat/stacks.svg')\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b41fbd2c-ec6f-4691-93e3-05be47b0b603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:00<00:00, 2518.44it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 1944.34it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 1705.98it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 730.66it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 1880.82it/s]\n",
      "<ipython-input-188-a8a715d4c4bf>:95: UserWarning: loadtxt: Empty input file: \"/media/cat/4TBSSD/yuki/AQ2/tif_files/AQ2am_Dec9_30Hz/rewarded_times.txt\"\n",
      "  rtimes = np.loadtxt(os.path.join(root_dir,\n",
      "100%|██████████| 110/110 [00:00<00:00, 1692.08it/s]\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "####### PLOT AVERAGE NUMBER OF LEVER PULLS #####\n",
    "################################################\n",
    "# plot # of lever pulls per session per animal as scatter plot\n",
    "import pandas as pd\n",
    "root_dir = '/media/cat/4TBSSD/yuki/'\n",
    "\n",
    "animal_ids = ['IA1','IA2','IA3','IJ1','IJ2','AQ2']\n",
    "session_id = 'all'\n",
    "\n",
    "plot_n_trials_per_session(root_dir,\n",
    "                         animal_id,\n",
    "                         session_id)\n",
    "\n",
    "#\n",
    "if False:\n",
    "    plt.savefig('/home/cat/n_trials_per_session.svg')\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6fd3a62b-5bbe-49cd-bfba-fac9fd2ae8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trials:  (165, 1800, 16)\n",
      "trials:  (82, 1800, 16)\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#### PLOT READINESS POTENTIAL FOR LOCKED OUT DATA ######\n",
    "########################################################\n",
    "from scipy.signal import butter, lfilter, filtfilt, hilbert, chirp\n",
    "\n",
    "def butter_lowpass(cutoff, nyq_freq, order=4):\n",
    "    normal_cutoff = float(cutoff) / nyq_freq\n",
    "    b, a = butter(order, normal_cutoff, btype='lowpass')\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq, nyq_freq, order=4):\n",
    "    # Source: https://github.com/guillaume-chevalier/filtering-stft-and-laplace-transform\n",
    "    b, a = butter_lowpass(cutoff_freq, nyq_freq, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "animal_ids = ['IA1','IA2','IA3','IJ1','IJ2','AQ2']\n",
    "animal_ids = ['IJ2']\n",
    "\n",
    "clrs = ['darkblue','red']\n",
    "lockouts = [0,21]  #\n",
    "\n",
    "max_trials_in_animal = [399,   # 21 sec min times\n",
    "                        385,\n",
    "                        96,\n",
    "                        137,\n",
    "                        82,\n",
    "                        318]\n",
    "\n",
    "\n",
    "# max_trials_in_animal = [601,   # 12 sec min trials\n",
    "#                         728,\n",
    "#                         310,\n",
    "#                         371,\n",
    "#                         197,\n",
    "#                         910]\n",
    "\n",
    "#\n",
    "plt.figure(figsize=(20,4))\n",
    "ctr=0\n",
    "\n",
    "# \n",
    "for animal_id in animal_ids:\n",
    "    ax=plt.subplot(1,6,ctr+1)\n",
    "    \n",
    "    for ctr_color, lockout in enumerate(lockouts): \n",
    "\n",
    "        data = np.load('/media/cat/4TBSSD/yuki/'+animal_id+'/super_sessions/alldata_body_and_nonreward_lockout_'+str(lockout)+'secLockout_[]bodyfeats.npz',\n",
    "                       allow_pickle=True)\n",
    "\n",
    "        names = data['names']\n",
    "        behaviors = data['behaviors']\n",
    "        trials = data['trials']\n",
    "\n",
    "        temp = []\n",
    "        for tr in trials:\n",
    "            if tr.shape[0]<=30:\n",
    "                temp.append(tr)\n",
    "        \n",
    "            \n",
    "            \n",
    "        trials = np.vstack(temp)\n",
    "        print (\"trials: \", trials.shape)\n",
    "        random = data['random']\n",
    "        random = np.vstack(random)\n",
    "        \n",
    "\n",
    "\n",
    "        #\n",
    "        if False:\n",
    "            maxes = max_trials_in_animal[ctr]\n",
    "            #n_tr = min(trials.shape[0],300)\n",
    "            idx = np.random.choice(np.arange(trials.shape[0]),maxes, replace=False)\n",
    "        else:\n",
    "            idx = np.arange(trials.shape[0])\n",
    "        \n",
    "        means = trials[idx].mean(0)\n",
    "        tt= np.arange(trials.shape[1])/30-30\n",
    "\n",
    "        #\n",
    "        feature_id = 4\n",
    "\n",
    "        #\n",
    "        x = tt.copy()\n",
    "\n",
    "        #\n",
    "        # analytic_signal = hilbert(means[:,feature_id])\n",
    "        # amplitude_envelope = np.abs(analytic_signal)\n",
    "        # amplitude_envelope = butter_lowpass_filter(amplitude_envelope,.5,30)\n",
    "\n",
    "        start = 0\n",
    "        end = 1050\n",
    "        t = means[:,feature_id][start:end]\n",
    "        \n",
    "        #t = butter_lowpass_filter(t,1,30)\n",
    "        \n",
    "        t = t/np.max(t)\n",
    "\n",
    "        # \n",
    "        x = x[start:end]\n",
    "        #amplitude_envelope = amplitude_envelope[start:end]\n",
    "\n",
    "        plt.plot(x, t, c=clrs[ctr_color], \n",
    "                 linewidth=5, \n",
    "                 alpha=0.6,\n",
    "                 label='Average session neural signal')\n",
    "        # plt.plot(x, amplitude_envelope, '--', c='black', linewidth=1, label=\"Hilbert transform envelope\")\n",
    "\n",
    "\n",
    "        #\n",
    "        plt.plot([x[0], x[-1]],[0,0],'--',c='black', linewidth=3)\n",
    "        plt.plot([x[900], x[900]],[-1,1],'--',c='black', linewidth=3)\n",
    "\n",
    "\n",
    "        #plt.plot(tt,means[:,feature_id],c='blue')\n",
    "        #plt.plot(t,random.mean(0)[:,4],c='red')\n",
    "        plt.xlim(-20,3)\n",
    "        #plt.title(animal_id+\" \" +str(lockout)+\"sec\")\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "    ctr+=1\n",
    "    \n",
    "if True:\n",
    "    plt.savefig('/home/cat/allaverages_'+str(lockouts)+'.svg')\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2661f8e0-96a3-4ee3-b27a-48249b2525aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Retrosplenial area, dorsal part, layer 1\n",
      "1 Retrosplenial area, lateral agranular part, layer 1\n",
      "2 Primary visual area, layer 1\n",
      "3 Primary somatosensory area, upper limb, layer 1\n",
      "4 Primary somatosensory area, lower limb, layer 1\n",
      "5 Primary somatosensory area, barrel field, layer 1\n",
      "6 Secondary motor area, layer 1\n",
      "7 Primary motor area, Layer 1\n",
      "8 Primary motor area, Layer 1\n",
      "9 Secondary motor area, layer 1\n",
      "10 Primary somatosensory area, barrel field, layer 1\n",
      "11 Primary somatosensory area, lower limb, layer 1\n",
      "12 Primary somatosensory area, upper limb, layer 1\n",
      "13 Primary visual area, layer 1\n",
      "14 Retrosplenial area, lateral agranular part, layer 1\n",
      "15 Retrosplenial area, dorsal part, layer 1\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/4TBSSD/yuki/IA1/super_sessions/alldata_body_and_nonreward_lockout_0secLockout_[]bodyfeats.npz',\n",
    "               allow_pickle=True)\n",
    "\n",
    "behaviors = data['all_area_names']\n",
    "for ctr,b in enumerate(behaviors[0]):\n",
    "    print (ctr, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d21c131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41,)\n",
      "10 IA3pm_Feb1_30Hz (30, 1800, 16)\n",
      "11 IA3pm_Feb2_30Hz (65, 1800, 16)\n",
      "12 IA3pm_Feb3_30Hz (94, 1800, 16)\n",
      "13 IA3pm_Feb4_30Hz (54, 1800, 16)\n",
      "14 IA3pm_Feb9_30Hz (11, 1800, 16)\n",
      "15 IA3pm_Feb11_30Hz (13, 1800, 16)\n",
      "16 IA3pm_Feb12_30Hz (83, 1800, 16)\n",
      "17 IA3pm_Feb15_30Hz (48, 1800, 16)\n",
      "18 IA3pm_Feb16_30Hz (66, 1800, 16)\n",
      "19 IA3pm_Feb17_30Hz (50, 1800, 16)\n",
      "20 IA3pm_Feb18_30Hz (38, 1800, 16)\n",
      "21 IA3pm_Feb19_30Hz (30, 1800, 16)\n",
      "22 IA3pm_Feb22_30Hz (24, 1800, 16)\n",
      "23 IA3pm_Feb23_30Hz (11, 1800, 16)\n",
      "24 IA3pm_Feb26_30Hz (67, 1800, 16)\n",
      "25 IA3pm_Feb29_30Hz (49, 1800, 16)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    d1 = np.load('/media/cat/4TBSSD/yuki/IA3/super_sessions/alldata_body_and_nonreward_lockout_0secLockout_[]bodyfeats.npz',\n",
    "                 allow_pickle=True)\n",
    "    trials = d1['trials']\n",
    "    print (trials.shape)\n",
    "\n",
    "    sessions2 = d1['all_session_names']\n",
    "    #print (sessions2)\n",
    "    for k in range(len(sessions2)):\n",
    "        if \"Feb\" in sessions2[k]:\n",
    "            print (k,sessions2[k], trials[k].shape)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "de9381d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 1800, 16)\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "#############################################\n",
    "#############################################\n",
    "session_id = 13\n",
    "feature_id = 4\n",
    "    \n",
    "#\n",
    "print (trials[session_id].shape)\n",
    "means = trials[session_id].mean(0)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot([-3,-3],[-30,100],'--',c='black')\n",
    "plt.plot([3,3],[-30,100],'--',c='black')\n",
    "t=np.arange(means.shape[0])/30-30\n",
    "plt.plot(t,means[:,feature_id])\n",
    "plt.title(sessions2[session_id])\n",
    "plt.xlim(-20,5)\n",
    "\n",
    "if True:\n",
    "    plt.savefig('/home/cat/example_oscillations.svg')\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac980db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f22311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37949c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c09633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3735304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b5666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc923e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ac878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed340a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
